{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.src.layers import Conv1D, BatchNormalization, LeakyReLU, Dropout, Dense, Input, SpatialDropout1D, MaxPooling1D, GlobalMaxPooling1D, concatenate\n",
    "\n",
    "from sources.utils import Config, zoom_frames, normalize_range, get_joint_collection_distances, pose_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convolution1D(x, filters, kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def convolutions_block(x, filters):\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = convolution1D(x, filters, 3)\n",
    "\n",
    "    return x\n",
    "\n",
    "def dense1D(x, filters):\n",
    "    x = Dense(filters, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_jcd_block(x, filters):\n",
    "    x = convolution1D(x ,filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_slow_motion_block(x, filters):\n",
    "    x = convolution1D(x, filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_fast_motion_block(x, filters):\n",
    "    x = convolution1D(x, filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_main_block(x, filters):\n",
    "    x = convolutions_block(x, filters * 2)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolutions_block(x, filters * 4)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolutions_block(x, filters * 8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_output_block(x, classes_number):\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = dense1D(x, 128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = dense1D(x, 128)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(classes_number, activation='softmax')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_DD_Net(model_config):\n",
    "    Distance = Input(name='Distance', shape=(model_config.frame_length, model_config.features_dimension))\n",
    "    Motion = Input(name='Motion', shape=(model_config.frame_length, model_config.joints_number, model_config.joints_dimension))\n",
    "    \n",
    "    slow_diff, fast_diff = pose_motion(Motion, model_config.frame_length)\n",
    "\n",
    "    # Joint Collection Distances\n",
    "    model = build_jcd_block(Distance, model_config.filters)\n",
    "\n",
    "    # Cartesian coordinates\n",
    "    slow_diff = build_slow_motion_block(slow_diff, model_config.filters)\n",
    "    fast_diff = build_fast_motion_block(fast_diff, model_config.filters)\n",
    "\n",
    "    model = concatenate([model, slow_diff, fast_diff])\n",
    "\n",
    "    model = build_main_block(model, model_config.filters)\n",
    "\n",
    "    model = build_output_block(model, model_config.classes_number)\n",
    "    \n",
    "    model = Model(inputs=[Distance, Motion], outputs=model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DD_Net = build_DD_Net(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Motion (InputLayer)         [(None, 32, 22, 2)]          0         []                            \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 32, 22, 2)            0         ['Motion[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 16, 22, 2)            0         ['Motion[0][0]']              \n",
      "                                                                                                  \n",
      " Distance (InputLayer)       [(None, 32, 231)]            0         []                            \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 32, 44)               0         ['lambda_3[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)           (None, 16, 22, 2)            0         ['lambda_4[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)          (None, 32, 32)               7392      ['Distance[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)          (None, 32, 32)               1408      ['reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)         (None, 16, 44)               0         ['lambda_5[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (None, 32, 32)               128       ['conv1d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (None, 32, 32)               128       ['conv1d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)          (None, 16, 32)               1408      ['reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 32, 32)               0         ['batch_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 32, 32)               0         ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 16, 32)               128       ['conv1d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout1d_12 (Spat  (None, 32, 32)               0         ['leaky_re_lu_17[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout1d_15 (Spat  (None, 32, 32)               0         ['leaky_re_lu_20[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 16, 32)               0         ['batch_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)          (None, 32, 16)               1536      ['spatial_dropout1d_12[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)          (None, 32, 16)               1536      ['spatial_dropout1d_15[0][0]']\n",
      "                                                                                                  \n",
      " spatial_dropout1d_18 (Spat  (None, 16, 32)               0         ['leaky_re_lu_23[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (None, 32, 16)               64        ['conv1d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 32, 16)               64        ['conv1d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)          (None, 16, 16)               1536      ['spatial_dropout1d_18[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 32, 16)               0         ['batch_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 32, 16)               0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 16, 16)               64        ['conv1d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout1d_13 (Spat  (None, 32, 16)               0         ['leaky_re_lu_18[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout1d_16 (Spat  (None, 32, 16)               0         ['leaky_re_lu_21[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 16, 16)               0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)          (None, 32, 16)               256       ['spatial_dropout1d_13[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)          (None, 32, 16)               256       ['spatial_dropout1d_16[0][0]']\n",
      "                                                                                                  \n",
      " spatial_dropout1d_19 (Spat  (None, 16, 16)               0         ['leaky_re_lu_24[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (None, 32, 16)               64        ['conv1d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 32, 16)               64        ['conv1d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)          (None, 16, 16)               256       ['spatial_dropout1d_19[0][0]']\n",
      "                                                                                                  \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 32, 16)               0         ['batch_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 16)               0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 16, 16)               64        ['conv1d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPoolin  (None, 16, 16)               0         ['leaky_re_lu_19[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPoolin  (None, 16, 16)               0         ['leaky_re_lu_22[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 16, 16)               0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " spatial_dropout1d_14 (Spat  (None, 16, 16)               0         ['max_pooling1d_4[0][0]']     \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout1d_17 (Spat  (None, 16, 16)               0         ['max_pooling1d_5[0][0]']     \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout1d_20 (Spat  (None, 16, 16)               0         ['leaky_re_lu_25[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 16, 48)               0         ['spatial_dropout1d_14[0][0]',\n",
      " )                                                                   'spatial_dropout1d_17[0][0]',\n",
      "                                                                     'spatial_dropout1d_20[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)          (None, 16, 32)               4608      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 16, 32)               128       ['conv1d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_26 (LeakyReLU)  (None, 16, 32)               0         ['batch_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)          (None, 16, 32)               3072      ['leaky_re_lu_26[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 16, 32)               128       ['conv1d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_27 (LeakyReLU)  (None, 16, 32)               0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_6 (MaxPoolin  (None, 8, 32)                0         ['leaky_re_lu_27[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout1d_21 (Spat  (None, 8, 32)                0         ['max_pooling1d_6[0][0]']     \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)          (None, 8, 64)                6144      ['spatial_dropout1d_21[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 8, 64)                256       ['conv1d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_28 (LeakyReLU)  (None, 8, 64)                0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)          (None, 8, 64)                12288     ['leaky_re_lu_28[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 8, 64)                256       ['conv1d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_29 (LeakyReLU)  (None, 8, 64)                0         ['batch_normalization_29[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_7 (MaxPoolin  (None, 4, 64)                0         ['leaky_re_lu_29[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout1d_22 (Spat  (None, 4, 64)                0         ['max_pooling1d_7[0][0]']     \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)          (None, 4, 128)               24576     ['spatial_dropout1d_22[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 4, 128)               512       ['conv1d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_30 (LeakyReLU)  (None, 4, 128)               0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)          (None, 4, 128)               49152     ['leaky_re_lu_30[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 4, 128)               512       ['conv1d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_31 (LeakyReLU)  (None, 4, 128)               0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " spatial_dropout1d_23 (Spat  (None, 4, 128)               0         ['leaky_re_lu_31[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Gl  (None, 128)                  0         ['spatial_dropout1d_23[0][0]']\n",
      " obalMaxPooling1D)                                                                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  16384     ['global_max_pooling1d_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 128)                  512       ['dense_3[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_32 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['leaky_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 128)                  16384     ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 128)                  512       ['dense_4[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_33 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['leaky_re_lu_33[0][0]']      \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 14)                   1806      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 153582 (599.93 KB)\n",
      "Trainable params: 151790 (592.93 KB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def prepare_data(filename: str):\n",
    "    data = pickle.load(open(config.data_directory + filename, \"rb\"))\n",
    "\n",
    "    Labels = []\n",
    "    Distances = []\n",
    "    Motion = []\n",
    "\n",
    "    print(f\"Preparing data from {filename}...\")\n",
    "\n",
    "    for i in tqdm(range(len(data['skeleton']))):\n",
    "        motion = np.copy(data['skeleton'][i]).reshape([-1, config.joints_number, config.joints_dimension])\n",
    "        motion = zoom_frames(motion, config.frame_length, config.joints_number, config.joints_dimension)\n",
    "        motion = normalize_range(motion)\n",
    "\n",
    "        label = np.zeros(config.classes_number)\n",
    "        label[data['label'][i] - 1] = 1\n",
    "\n",
    "        distance = get_joint_collection_distances(motion, config)\n",
    "\n",
    "        Distances.append(distance)\n",
    "        Motion.append(motion)\n",
    "        Labels.append(label)\n",
    "\n",
    "    Distances = np.stack(Distances)\n",
    "    Motion = np.stack(Motion)\n",
    "    Labels = np.stack(Labels)\n",
    "\n",
    "    return [Distances, Motion], Labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data from train.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:03<00:00, 519.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data from valid.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:01<00:00, 539.24it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = prepare_data(\"train.pkl\")\n",
    "X_valid, Y_valid = prepare_data(\"valid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",\n",
    "               optimizer=keras.optimizers.legacy.Adam(lr),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, X_valid, Y_valid, epochs=100):\n",
    "    callbacks = []\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                                     factor=0.5,\n",
    "                                                     patience=5,\n",
    "                                                     cooldown=5,\n",
    "                                                     min_lr=5e-6)\n",
    "    callbacks.append(lr_scheduler)\n",
    "    \n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        batch_size=len(Y_train),\n",
    "                        epochs=epochs,\n",
    "                        verbose=True,\n",
    "                        shuffle=True,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=(X_valid, Y_valid)\n",
    "                        )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 05:18:17.378151: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.1855 - accuracy: 0.0735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 05:18:19.980066: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 3.1855 - accuracy: 0.0735 - val_loss: 2.7428 - val_accuracy: 0.0679 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 2.9730 - accuracy: 0.0893 - val_loss: 2.6632 - val_accuracy: 0.1036 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 2.8247 - accuracy: 0.1260 - val_loss: 2.6331 - val_accuracy: 0.1405 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.7062 - accuracy: 0.1367 - val_loss: 2.6233 - val_accuracy: 0.1262 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.5963 - accuracy: 0.1582 - val_loss: 2.6178 - val_accuracy: 0.0905 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.5103 - accuracy: 0.1776 - val_loss: 2.6112 - val_accuracy: 0.0845 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.3691 - accuracy: 0.2204 - val_loss: 2.5968 - val_accuracy: 0.0833 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 2.3292 - accuracy: 0.2459 - val_loss: 2.5760 - val_accuracy: 0.0881 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.2710 - accuracy: 0.2469 - val_loss: 2.5479 - val_accuracy: 0.0905 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1978 - accuracy: 0.2735 - val_loss: 2.5151 - val_accuracy: 0.1036 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.1142 - accuracy: 0.2908 - val_loss: 2.4855 - val_accuracy: 0.1286 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.0570 - accuracy: 0.3296 - val_loss: 2.4558 - val_accuracy: 0.1476 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 2.0193 - accuracy: 0.3321 - val_loss: 2.4246 - val_accuracy: 0.1619 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.9351 - accuracy: 0.3587 - val_loss: 2.3970 - val_accuracy: 0.1762 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.8983 - accuracy: 0.3745 - val_loss: 2.3675 - val_accuracy: 0.1833 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 1.8020 - accuracy: 0.4184 - val_loss: 2.3405 - val_accuracy: 0.1893 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.7832 - accuracy: 0.4163 - val_loss: 2.3163 - val_accuracy: 0.1952 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.7224 - accuracy: 0.4418 - val_loss: 2.2898 - val_accuracy: 0.2024 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 1.6715 - accuracy: 0.4546 - val_loss: 2.2658 - val_accuracy: 0.2167 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.6210 - accuracy: 0.4724 - val_loss: 2.2448 - val_accuracy: 0.2333 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.5713 - accuracy: 0.5046 - val_loss: 2.2270 - val_accuracy: 0.2440 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 1.5047 - accuracy: 0.5250 - val_loss: 2.2115 - val_accuracy: 0.2524 - lr: 0.0010\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.4664 - accuracy: 0.5327 - val_loss: 2.1998 - val_accuracy: 0.2560 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.4206 - accuracy: 0.5633 - val_loss: 2.1859 - val_accuracy: 0.2536 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.3640 - accuracy: 0.5811 - val_loss: 2.1761 - val_accuracy: 0.2619 - lr: 0.0010\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.3219 - accuracy: 0.6107 - val_loss: 2.1697 - val_accuracy: 0.2726 - lr: 0.0010\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.2768 - accuracy: 0.6077 - val_loss: 2.1649 - val_accuracy: 0.2690 - lr: 0.0010\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 1.2399 - accuracy: 0.6051 - val_loss: 2.1632 - val_accuracy: 0.2810 - lr: 0.0010\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.2056 - accuracy: 0.6286 - val_loss: 2.1590 - val_accuracy: 0.2929 - lr: 0.0010\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.1468 - accuracy: 0.6566 - val_loss: 2.1530 - val_accuracy: 0.3071 - lr: 0.0010\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.1113 - accuracy: 0.6663 - val_loss: 2.1406 - val_accuracy: 0.3143 - lr: 0.0010\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.0899 - accuracy: 0.6745 - val_loss: 2.1260 - val_accuracy: 0.3202 - lr: 0.0010\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1.0650 - accuracy: 0.6801 - val_loss: 2.1099 - val_accuracy: 0.3298 - lr: 0.0010\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.0007 - accuracy: 0.7020 - val_loss: 2.0940 - val_accuracy: 0.3321 - lr: 0.0010\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 1.0109 - accuracy: 0.6923 - val_loss: 2.0732 - val_accuracy: 0.3298 - lr: 0.0010\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.9644 - accuracy: 0.7128 - val_loss: 2.0520 - val_accuracy: 0.3274 - lr: 0.0010\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.9103 - accuracy: 0.7301 - val_loss: 2.0311 - val_accuracy: 0.3345 - lr: 0.0010\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.8892 - accuracy: 0.7444 - val_loss: 2.0180 - val_accuracy: 0.3345 - lr: 0.0010\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.8428 - accuracy: 0.7515 - val_loss: 2.0052 - val_accuracy: 0.3345 - lr: 0.0010\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.8353 - accuracy: 0.7551 - val_loss: 2.0010 - val_accuracy: 0.3357 - lr: 0.0010\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.8142 - accuracy: 0.7668 - val_loss: 2.0005 - val_accuracy: 0.3381 - lr: 0.0010\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7872 - accuracy: 0.7668 - val_loss: 1.9954 - val_accuracy: 0.3357 - lr: 0.0010\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.7819 - accuracy: 0.7648 - val_loss: 1.9927 - val_accuracy: 0.3333 - lr: 0.0010\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.7250 - accuracy: 0.7827 - val_loss: 1.9884 - val_accuracy: 0.3310 - lr: 0.0010\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.7221 - accuracy: 0.7878 - val_loss: 1.9825 - val_accuracy: 0.3298 - lr: 0.0010\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.6761 - accuracy: 0.8077 - val_loss: 1.9820 - val_accuracy: 0.3298 - lr: 0.0010\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.6729 - accuracy: 0.8077 - val_loss: 1.9726 - val_accuracy: 0.3286 - lr: 0.0010\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.6684 - accuracy: 0.8026 - val_loss: 1.9606 - val_accuracy: 0.3310 - lr: 0.0010\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.6425 - accuracy: 0.8199 - val_loss: 1.9557 - val_accuracy: 0.3298 - lr: 0.0010\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6426 - accuracy: 0.8102 - val_loss: 1.9397 - val_accuracy: 0.3381 - lr: 0.0010\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.6142 - accuracy: 0.8276 - val_loss: 1.9224 - val_accuracy: 0.3440 - lr: 0.0010\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.5772 - accuracy: 0.8357 - val_loss: 1.9086 - val_accuracy: 0.3476 - lr: 0.0010\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.6166 - accuracy: 0.8209 - val_loss: 1.8994 - val_accuracy: 0.3464 - lr: 0.0010\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.5582 - accuracy: 0.8413 - val_loss: 1.8859 - val_accuracy: 0.3548 - lr: 0.0010\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.5661 - accuracy: 0.8388 - val_loss: 1.8601 - val_accuracy: 0.3643 - lr: 0.0010\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5458 - accuracy: 0.8454 - val_loss: 1.8276 - val_accuracy: 0.3774 - lr: 0.0010\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.5051 - accuracy: 0.8602 - val_loss: 1.7922 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4954 - accuracy: 0.8602 - val_loss: 1.7568 - val_accuracy: 0.4119 - lr: 0.0010\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4855 - accuracy: 0.8622 - val_loss: 1.7174 - val_accuracy: 0.4250 - lr: 0.0010\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4833 - accuracy: 0.8638 - val_loss: 1.6972 - val_accuracy: 0.4286 - lr: 0.0010\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.4836 - accuracy: 0.8704 - val_loss: 1.6708 - val_accuracy: 0.4417 - lr: 0.0010\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.4683 - accuracy: 0.8679 - val_loss: 1.6387 - val_accuracy: 0.4619 - lr: 0.0010\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4477 - accuracy: 0.8730 - val_loss: 1.6080 - val_accuracy: 0.4726 - lr: 0.0010\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4654 - accuracy: 0.8730 - val_loss: 1.5781 - val_accuracy: 0.4845 - lr: 0.0010\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4254 - accuracy: 0.8837 - val_loss: 1.5353 - val_accuracy: 0.5012 - lr: 0.0010\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4284 - accuracy: 0.8847 - val_loss: 1.4857 - val_accuracy: 0.5190 - lr: 0.0010\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.4400 - accuracy: 0.8735 - val_loss: 1.4342 - val_accuracy: 0.5310 - lr: 0.0010\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.4084 - accuracy: 0.8918 - val_loss: 1.3989 - val_accuracy: 0.5381 - lr: 0.0010\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 0.4164 - accuracy: 0.8862 - val_loss: 1.3687 - val_accuracy: 0.5464 - lr: 0.0010\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3867 - accuracy: 0.8969 - val_loss: 1.3389 - val_accuracy: 0.5583 - lr: 0.0010\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3736 - accuracy: 0.8980 - val_loss: 1.3103 - val_accuracy: 0.5631 - lr: 0.0010\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.3864 - accuracy: 0.8898 - val_loss: 1.2931 - val_accuracy: 0.5714 - lr: 0.0010\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3796 - accuracy: 0.8929 - val_loss: 1.2751 - val_accuracy: 0.5821 - lr: 0.0010\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.3786 - accuracy: 0.8929 - val_loss: 1.2537 - val_accuracy: 0.5929 - lr: 0.0010\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.3514 - accuracy: 0.9000 - val_loss: 1.2380 - val_accuracy: 0.6012 - lr: 0.0010\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.3660 - accuracy: 0.8990 - val_loss: 1.2068 - val_accuracy: 0.6262 - lr: 0.0010\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.3514 - accuracy: 0.9026 - val_loss: 1.1809 - val_accuracy: 0.6321 - lr: 0.0010\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.3395 - accuracy: 0.9061 - val_loss: 1.1520 - val_accuracy: 0.6476 - lr: 0.0010\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 0.3430 - accuracy: 0.9097 - val_loss: 1.1264 - val_accuracy: 0.6536 - lr: 0.0010\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 0.3147 - accuracy: 0.9128 - val_loss: 1.0977 - val_accuracy: 0.6702 - lr: 0.0010\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3293 - accuracy: 0.9122 - val_loss: 1.0683 - val_accuracy: 0.6738 - lr: 0.0010\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3182 - accuracy: 0.9173 - val_loss: 1.0380 - val_accuracy: 0.6857 - lr: 0.0010\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.3140 - accuracy: 0.9122 - val_loss: 1.0117 - val_accuracy: 0.6964 - lr: 0.0010\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3033 - accuracy: 0.9133 - val_loss: 0.9846 - val_accuracy: 0.7048 - lr: 0.0010\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.3085 - accuracy: 0.9194 - val_loss: 0.9610 - val_accuracy: 0.7131 - lr: 0.0010\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.2833 - accuracy: 0.9281 - val_loss: 0.9419 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2908 - accuracy: 0.9235 - val_loss: 0.9290 - val_accuracy: 0.7250 - lr: 0.0010\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 0.2998 - accuracy: 0.9219 - val_loss: 0.9260 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 0.2863 - accuracy: 0.9245 - val_loss: 0.9159 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.2758 - accuracy: 0.9179 - val_loss: 0.9054 - val_accuracy: 0.7298 - lr: 0.0010\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.2758 - accuracy: 0.9281 - val_loss: 0.9048 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2752 - accuracy: 0.9276 - val_loss: 0.9040 - val_accuracy: 0.7167 - lr: 0.0010\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.2582 - accuracy: 0.9255 - val_loss: 0.8995 - val_accuracy: 0.7202 - lr: 0.0010\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2588 - accuracy: 0.9311 - val_loss: 0.8847 - val_accuracy: 0.7262 - lr: 0.0010\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2564 - accuracy: 0.9311 - val_loss: 0.8558 - val_accuracy: 0.7321 - lr: 0.0010\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2524 - accuracy: 0.9327 - val_loss: 0.8192 - val_accuracy: 0.7464 - lr: 0.0010\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.2555 - accuracy: 0.9321 - val_loss: 0.7821 - val_accuracy: 0.7643 - lr: 0.0010\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2595 - accuracy: 0.9281 - val_loss: 0.7457 - val_accuracy: 0.7762 - lr: 0.0010\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2371 - accuracy: 0.9378 - val_loss: 0.7091 - val_accuracy: 0.7881 - lr: 0.0010\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 0.2349 - accuracy: 0.9332 - val_loss: 0.6785 - val_accuracy: 0.7964 - lr: 0.0010\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2324 - accuracy: 0.9367 - val_loss: 0.6620 - val_accuracy: 0.8048 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2288 - accuracy: 0.9372 - val_loss: 0.6561 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.2270 - accuracy: 0.9423 - val_loss: 0.6632 - val_accuracy: 0.8107 - lr: 0.0010\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.2335 - accuracy: 0.9357 - val_loss: 0.6784 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2267 - accuracy: 0.9372 - val_loss: 0.6960 - val_accuracy: 0.7940 - lr: 0.0010\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.2128 - accuracy: 0.9439 - val_loss: 0.7124 - val_accuracy: 0.7869 - lr: 0.0010\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2256 - accuracy: 0.9388 - val_loss: 0.7198 - val_accuracy: 0.7869 - lr: 0.0010\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2182 - accuracy: 0.9413 - val_loss: 0.7100 - val_accuracy: 0.7893 - lr: 0.0010\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2185 - accuracy: 0.9423 - val_loss: 0.6867 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1933 - accuracy: 0.9474 - val_loss: 0.6626 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1988 - accuracy: 0.9444 - val_loss: 0.6397 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2026 - accuracy: 0.9383 - val_loss: 0.6121 - val_accuracy: 0.8179 - lr: 0.0010\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2083 - accuracy: 0.9423 - val_loss: 0.5867 - val_accuracy: 0.8274 - lr: 0.0010\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.2062 - accuracy: 0.9480 - val_loss: 0.5689 - val_accuracy: 0.8321 - lr: 0.0010\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1904 - accuracy: 0.9429 - val_loss: 0.5652 - val_accuracy: 0.8369 - lr: 0.0010\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1949 - accuracy: 0.9500 - val_loss: 0.5590 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1859 - accuracy: 0.9495 - val_loss: 0.5565 - val_accuracy: 0.8321 - lr: 0.0010\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2059 - accuracy: 0.9495 - val_loss: 0.5530 - val_accuracy: 0.8369 - lr: 0.0010\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1834 - accuracy: 0.9536 - val_loss: 0.5536 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1808 - accuracy: 0.9505 - val_loss: 0.5568 - val_accuracy: 0.8321 - lr: 0.0010\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1686 - accuracy: 0.9612 - val_loss: 0.5568 - val_accuracy: 0.8286 - lr: 0.0010\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1703 - accuracy: 0.9510 - val_loss: 0.5467 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1750 - accuracy: 0.9490 - val_loss: 0.5229 - val_accuracy: 0.8393 - lr: 0.0010\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1757 - accuracy: 0.9526 - val_loss: 0.4933 - val_accuracy: 0.8476 - lr: 0.0010\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1630 - accuracy: 0.9536 - val_loss: 0.4715 - val_accuracy: 0.8619 - lr: 0.0010\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1687 - accuracy: 0.9531 - val_loss: 0.4565 - val_accuracy: 0.8690 - lr: 0.0010\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1696 - accuracy: 0.9505 - val_loss: 0.4411 - val_accuracy: 0.8726 - lr: 0.0010\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1621 - accuracy: 0.9582 - val_loss: 0.4273 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1631 - accuracy: 0.9582 - val_loss: 0.4171 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1698 - accuracy: 0.9546 - val_loss: 0.4113 - val_accuracy: 0.8833 - lr: 0.0010\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1646 - accuracy: 0.9536 - val_loss: 0.4021 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1521 - accuracy: 0.9566 - val_loss: 0.3938 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1573 - accuracy: 0.9571 - val_loss: 0.3874 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1459 - accuracy: 0.9571 - val_loss: 0.3846 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1564 - accuracy: 0.9622 - val_loss: 0.3862 - val_accuracy: 0.8881 - lr: 0.0010\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1452 - accuracy: 0.9597 - val_loss: 0.3898 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1573 - accuracy: 0.9541 - val_loss: 0.4006 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1384 - accuracy: 0.9622 - val_loss: 0.4155 - val_accuracy: 0.8786 - lr: 0.0010\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1493 - accuracy: 0.9577 - val_loss: 0.4280 - val_accuracy: 0.8702 - lr: 0.0010\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1497 - accuracy: 0.9648 - val_loss: 0.4308 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1321 - accuracy: 0.9694 - val_loss: 0.4162 - val_accuracy: 0.8798 - lr: 0.0010\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1446 - accuracy: 0.9582 - val_loss: 0.3949 - val_accuracy: 0.8857 - lr: 0.0010\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1365 - accuracy: 0.9597 - val_loss: 0.3771 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.1280 - accuracy: 0.9673 - val_loss: 0.3701 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1287 - accuracy: 0.9653 - val_loss: 0.3712 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1318 - accuracy: 0.9628 - val_loss: 0.3717 - val_accuracy: 0.8929 - lr: 0.0010\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1268 - accuracy: 0.9673 - val_loss: 0.3744 - val_accuracy: 0.8905 - lr: 0.0010\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1269 - accuracy: 0.9689 - val_loss: 0.3784 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1265 - accuracy: 0.9658 - val_loss: 0.3736 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1172 - accuracy: 0.9704 - val_loss: 0.3648 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1115 - accuracy: 0.9694 - val_loss: 0.3668 - val_accuracy: 0.8988 - lr: 0.0010\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1318 - accuracy: 0.9602 - val_loss: 0.3600 - val_accuracy: 0.9024 - lr: 0.0010\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1218 - accuracy: 0.9679 - val_loss: 0.3544 - val_accuracy: 0.9060 - lr: 0.0010\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1198 - accuracy: 0.9699 - val_loss: 0.3410 - val_accuracy: 0.9083 - lr: 0.0010\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1202 - accuracy: 0.9643 - val_loss: 0.3316 - val_accuracy: 0.9107 - lr: 0.0010\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1295 - accuracy: 0.9648 - val_loss: 0.3233 - val_accuracy: 0.9119 - lr: 0.0010\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1108 - accuracy: 0.9776 - val_loss: 0.3195 - val_accuracy: 0.9143 - lr: 5.0000e-04\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1065 - accuracy: 0.9735 - val_loss: 0.3167 - val_accuracy: 0.9143 - lr: 5.0000e-04\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1202 - accuracy: 0.9699 - val_loss: 0.3128 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1245 - accuracy: 0.9658 - val_loss: 0.3089 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1041 - accuracy: 0.9755 - val_loss: 0.3088 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1042 - accuracy: 0.9699 - val_loss: 0.3091 - val_accuracy: 0.9179 - lr: 5.0000e-04\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1166 - accuracy: 0.9668 - val_loss: 0.3092 - val_accuracy: 0.9190 - lr: 5.0000e-04\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1040 - accuracy: 0.9750 - val_loss: 0.3090 - val_accuracy: 0.9179 - lr: 5.0000e-04\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1047 - accuracy: 0.9694 - val_loss: 0.3076 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0964 - accuracy: 0.9760 - val_loss: 0.3044 - val_accuracy: 0.9143 - lr: 5.0000e-04\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1104 - accuracy: 0.9694 - val_loss: 0.3012 - val_accuracy: 0.9167 - lr: 5.0000e-04\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0982 - accuracy: 0.9770 - val_loss: 0.2952 - val_accuracy: 0.9202 - lr: 5.0000e-04\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1100 - accuracy: 0.9719 - val_loss: 0.2921 - val_accuracy: 0.9202 - lr: 5.0000e-04\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1031 - accuracy: 0.9724 - val_loss: 0.2862 - val_accuracy: 0.9226 - lr: 5.0000e-04\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1084 - accuracy: 0.9709 - val_loss: 0.2823 - val_accuracy: 0.9238 - lr: 5.0000e-04\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1070 - accuracy: 0.9694 - val_loss: 0.2806 - val_accuracy: 0.9214 - lr: 2.5000e-04\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0990 - accuracy: 0.9724 - val_loss: 0.2792 - val_accuracy: 0.9202 - lr: 2.5000e-04\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1055 - accuracy: 0.9745 - val_loss: 0.2788 - val_accuracy: 0.9202 - lr: 2.5000e-04\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0952 - accuracy: 0.9755 - val_loss: 0.2768 - val_accuracy: 0.9214 - lr: 2.5000e-04\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1052 - accuracy: 0.9719 - val_loss: 0.2753 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1091 - accuracy: 0.9679 - val_loss: 0.2747 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0973 - accuracy: 0.9735 - val_loss: 0.2741 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0967 - accuracy: 0.9781 - val_loss: 0.2735 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1042 - accuracy: 0.9740 - val_loss: 0.2734 - val_accuracy: 0.9214 - lr: 2.5000e-04\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0876 - accuracy: 0.9786 - val_loss: 0.2730 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1010 - accuracy: 0.9724 - val_loss: 0.2729 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1064 - accuracy: 0.9709 - val_loss: 0.2727 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1057 - accuracy: 0.9724 - val_loss: 0.2726 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0990 - accuracy: 0.9750 - val_loss: 0.2724 - val_accuracy: 0.9202 - lr: 1.2500e-04\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0844 - accuracy: 0.9827 - val_loss: 0.2722 - val_accuracy: 0.9202 - lr: 1.2500e-04\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0872 - accuracy: 0.9801 - val_loss: 0.2722 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0923 - accuracy: 0.9776 - val_loss: 0.2719 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0960 - accuracy: 0.9740 - val_loss: 0.2713 - val_accuracy: 0.9226 - lr: 1.2500e-04\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0936 - accuracy: 0.9781 - val_loss: 0.2701 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0870 - accuracy: 0.9796 - val_loss: 0.2695 - val_accuracy: 0.9214 - lr: 1.2500e-04\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0986 - accuracy: 0.9755 - val_loss: 0.2686 - val_accuracy: 0.9214 - lr: 6.2500e-05\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0951 - accuracy: 0.9776 - val_loss: 0.2676 - val_accuracy: 0.9214 - lr: 6.2500e-05\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0920 - accuracy: 0.9750 - val_loss: 0.2666 - val_accuracy: 0.9214 - lr: 6.2500e-05\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0846 - accuracy: 0.9796 - val_loss: 0.2656 - val_accuracy: 0.9226 - lr: 6.2500e-05\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0917 - accuracy: 0.9776 - val_loss: 0.2647 - val_accuracy: 0.9226 - lr: 6.2500e-05\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0949 - accuracy: 0.9776 - val_loss: 0.2638 - val_accuracy: 0.9238 - lr: 6.2500e-05\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.0983 - accuracy: 0.9735 - val_loss: 0.2630 - val_accuracy: 0.9238 - lr: 6.2500e-05\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1024 - accuracy: 0.9724 - val_loss: 0.2622 - val_accuracy: 0.9238 - lr: 6.2500e-05\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1035 - accuracy: 0.9735 - val_loss: 0.2617 - val_accuracy: 0.9238 - lr: 6.2500e-05\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1096 - accuracy: 0.9704 - val_loss: 0.2610 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1038 - accuracy: 0.9709 - val_loss: 0.2602 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0969 - accuracy: 0.9755 - val_loss: 0.2595 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0951 - accuracy: 0.9786 - val_loss: 0.2589 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1042 - accuracy: 0.9730 - val_loss: 0.2583 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1100 - accuracy: 0.9689 - val_loss: 0.2576 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 0.2572 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0952 - accuracy: 0.9730 - val_loss: 0.2566 - val_accuracy: 0.9250 - lr: 3.1250e-05\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0846 - accuracy: 0.9796 - val_loss: 0.2560 - val_accuracy: 0.9262 - lr: 3.1250e-05\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.1025 - accuracy: 0.9745 - val_loss: 0.2555 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0893 - accuracy: 0.9770 - val_loss: 0.2550 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0977 - accuracy: 0.9755 - val_loss: 0.2547 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1129 - accuracy: 0.9719 - val_loss: 0.2543 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0980 - accuracy: 0.9755 - val_loss: 0.2539 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0914 - accuracy: 0.9735 - val_loss: 0.2536 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0963 - accuracy: 0.9730 - val_loss: 0.2534 - val_accuracy: 0.9262 - lr: 1.5625e-05\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0977 - accuracy: 0.9745 - val_loss: 0.2531 - val_accuracy: 0.9274 - lr: 1.5625e-05\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0865 - accuracy: 0.9806 - val_loss: 0.2528 - val_accuracy: 0.9274 - lr: 1.5625e-05\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0960 - accuracy: 0.9770 - val_loss: 0.2526 - val_accuracy: 0.9274 - lr: 7.8125e-06\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0864 - accuracy: 0.9801 - val_loss: 0.2524 - val_accuracy: 0.9274 - lr: 7.8125e-06\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0957 - accuracy: 0.9750 - val_loss: 0.2522 - val_accuracy: 0.9274 - lr: 7.8125e-06\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0959 - accuracy: 0.9770 - val_loss: 0.2520 - val_accuracy: 0.9274 - lr: 7.8125e-06\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.1015 - accuracy: 0.9760 - val_loss: 0.2518 - val_accuracy: 0.9274 - lr: 7.8125e-06\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1129 - accuracy: 0.9689 - val_loss: 0.2516 - val_accuracy: 0.9286 - lr: 7.8125e-06\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0939 - accuracy: 0.9760 - val_loss: 0.2514 - val_accuracy: 0.9286 - lr: 7.8125e-06\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1071 - accuracy: 0.9709 - val_loss: 0.2512 - val_accuracy: 0.9298 - lr: 7.8125e-06\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1036 - accuracy: 0.9714 - val_loss: 0.2511 - val_accuracy: 0.9298 - lr: 7.8125e-06\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0947 - accuracy: 0.9776 - val_loss: 0.2509 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0845 - accuracy: 0.9837 - val_loss: 0.2508 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0992 - accuracy: 0.9740 - val_loss: 0.2507 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0839 - accuracy: 0.9806 - val_loss: 0.2506 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0901 - accuracy: 0.9760 - val_loss: 0.2505 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1043 - accuracy: 0.9755 - val_loss: 0.2504 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0944 - accuracy: 0.9760 - val_loss: 0.2504 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.1104 - accuracy: 0.9699 - val_loss: 0.2503 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.0928 - accuracy: 0.9776 - val_loss: 0.2502 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.0853 - accuracy: 0.9827 - val_loss: 0.2502 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0932 - accuracy: 0.9760 - val_loss: 0.2502 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1047 - accuracy: 0.9760 - val_loss: 0.2501 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1028 - accuracy: 0.9724 - val_loss: 0.2501 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1048 - accuracy: 0.9724 - val_loss: 0.2501 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.0944 - accuracy: 0.9745 - val_loss: 0.2500 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.0951 - accuracy: 0.9760 - val_loss: 0.2500 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0994 - accuracy: 0.9755 - val_loss: 0.2499 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1012 - accuracy: 0.9730 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1022 - accuracy: 0.9714 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0927 - accuracy: 0.9770 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0983 - accuracy: 0.9719 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1069 - accuracy: 0.9719 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0941 - accuracy: 0.9770 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0894 - accuracy: 0.9776 - val_loss: 0.2499 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1038 - accuracy: 0.9689 - val_loss: 0.2500 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 0.0791 - accuracy: 0.9821 - val_loss: 0.2500 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.0894 - accuracy: 0.9786 - val_loss: 0.2501 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0992 - accuracy: 0.9745 - val_loss: 0.2501 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0940 - accuracy: 0.9740 - val_loss: 0.2502 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.0891 - accuracy: 0.9740 - val_loss: 0.2502 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0939 - accuracy: 0.9760 - val_loss: 0.2503 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0915 - accuracy: 0.9765 - val_loss: 0.2504 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1047 - accuracy: 0.9724 - val_loss: 0.2504 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0921 - accuracy: 0.9776 - val_loss: 0.2506 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0989 - accuracy: 0.9740 - val_loss: 0.2507 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0965 - accuracy: 0.9776 - val_loss: 0.2508 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1003 - accuracy: 0.9730 - val_loss: 0.2508 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0939 - accuracy: 0.9755 - val_loss: 0.2509 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0987 - accuracy: 0.9735 - val_loss: 0.2509 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0936 - accuracy: 0.9750 - val_loss: 0.2510 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0924 - accuracy: 0.9770 - val_loss: 0.2511 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.0863 - accuracy: 0.9811 - val_loss: 0.2511 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0910 - accuracy: 0.9806 - val_loss: 0.2511 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1004 - accuracy: 0.9760 - val_loss: 0.2512 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0889 - accuracy: 0.9755 - val_loss: 0.2513 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0903 - accuracy: 0.9791 - val_loss: 0.2513 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0817 - accuracy: 0.9801 - val_loss: 0.2514 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0922 - accuracy: 0.9719 - val_loss: 0.2514 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1012 - accuracy: 0.9765 - val_loss: 0.2514 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0903 - accuracy: 0.9750 - val_loss: 0.2515 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0952 - accuracy: 0.9750 - val_loss: 0.2515 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.0963 - accuracy: 0.9765 - val_loss: 0.2516 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1051 - accuracy: 0.9740 - val_loss: 0.2516 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1016 - accuracy: 0.9724 - val_loss: 0.2517 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0920 - accuracy: 0.9791 - val_loss: 0.2517 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1046 - accuracy: 0.9714 - val_loss: 0.2518 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0853 - accuracy: 0.9801 - val_loss: 0.2518 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.1047 - accuracy: 0.9745 - val_loss: 0.2519 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0850 - accuracy: 0.9801 - val_loss: 0.2520 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.0980 - accuracy: 0.9765 - val_loss: 0.2521 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0987 - accuracy: 0.9740 - val_loss: 0.2522 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0992 - accuracy: 0.9694 - val_loss: 0.2522 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1005 - accuracy: 0.9755 - val_loss: 0.2523 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0946 - accuracy: 0.9755 - val_loss: 0.2523 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0941 - accuracy: 0.9760 - val_loss: 0.2523 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0998 - accuracy: 0.9745 - val_loss: 0.2524 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0993 - accuracy: 0.9755 - val_loss: 0.2524 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0917 - accuracy: 0.9781 - val_loss: 0.2525 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1008 - accuracy: 0.9709 - val_loss: 0.2526 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.0821 - accuracy: 0.9816 - val_loss: 0.2526 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0885 - accuracy: 0.9786 - val_loss: 0.2527 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0908 - accuracy: 0.9786 - val_loss: 0.2528 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0962 - accuracy: 0.9750 - val_loss: 0.2529 - val_accuracy: 0.9333 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "DD_Net, training_history = train(DD_Net, X_train, Y_train, X_valid, Y_valid, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DD_Net.save_weights('../models/ddnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(training_history.history['accuracy'])\n",
    "plt.plot(training_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 05:19:15.998920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 2s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "2.0051510334014893"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "y = DD_Net.predict(X_train)\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = DD_Net.predict(X_valid)\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_valid, axis=1), np.argmax(Y_pred, axis=1))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.src.layers import Conv1D, BatchNormalization, LeakyReLU, Dropout, Dense, Input, SpatialDropout1D, MaxPooling1D, GlobalMaxPooling1D, concatenate\n",
    "\n",
    "from sources.utils import Config, zoom_frames, normalize_range, get_joint_collection_distances, pose_motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def convolution1D(x, filters, kernel):\n",
    "    x = Conv1D(filters, kernel_size=kernel, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def convolutions_block(x, filters):\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = convolution1D(x, filters, 3)\n",
    "\n",
    "    return x\n",
    "\n",
    "def dense1D(x, filters):\n",
    "    x = Dense(filters, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_jcd_block(x, filters):\n",
    "    # Joint Collection Distances\n",
    "    x = convolution1D(x ,filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_slow_motion_block(x, filters):\n",
    "    # Slow motion\n",
    "    x = convolution1D(x, filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters,1)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_fast_motion_block(x, filters):\n",
    "    # Fast motion\n",
    "    x = convolution1D(x, filters * 2, 1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters, 3)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolution1D(x, filters,1)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_main_block(x, filters):\n",
    "    x = convolutions_block(x, filters * 2)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolutions_block(x, filters * 4)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    x = convolutions_block(x, filters * 8)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_output_block(x, classes_number):\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "    x = dense1D(x, 128)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = dense1D(x, 128)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(classes_number, activation='softmax')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_DD_Net(model_config):\n",
    "    Distance = Input(name='Distance', shape=(model_config.frame_length, model_config.features_dimension))\n",
    "    Motion = Input(name='Motion', shape=(model_config.frame_length, model_config.joints_number, model_config.joints_dimension))\n",
    "    \n",
    "    slow_diff, fast_diff = pose_motion(Motion, model_config.frame_length)\n",
    "    model = build_jcd_block(Distance, model_config.filters)\n",
    "\n",
    "    # Cartesian coordinates\n",
    "    slow_diff = build_slow_motion_block(slow_diff, model_config.filters)\n",
    "    fast_diff = build_fast_motion_block(fast_diff, model_config.filters)\n",
    "\n",
    "    model = concatenate([model, slow_diff, fast_diff])\n",
    "    model = build_main_block(model, model_config.filters)\n",
    "\n",
    "    model = build_output_block(model, model_config.classes_number)\n",
    "    \n",
    "    model = Model(inputs=[Distance, Motion], outputs=model)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 04:41:48.260179: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-08-03 04:41:48.260202: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-08-03 04:41:48.260205: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-08-03 04:41:48.260385: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-03 04:41:48.260398: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "DD_Net = build_DD_Net(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " Motion (InputLayer)         [(None, 32, 22, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 32, 22, 3)            0         ['Motion[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 16, 22, 3)            0         ['Motion[0][0]']              \n",
      "                                                                                                  \n",
      " Distance (InputLayer)       [(None, 32, 231)]            0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 32, 66)               0         ['lambda[0][0]']              \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 16, 22, 3)            0         ['lambda_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 32, 32)               7392      ['Distance[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)           (None, 32, 32)               2112      ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 16, 66)               0         ['lambda_2[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 32, 32)               128       ['conv1d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 32, 32)               128       ['conv1d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)           (None, 16, 32)               2112      ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32)               0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32)               0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 16, 32)               128       ['conv1d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout1d (Spatial  (None, 32, 32)               0         ['leaky_re_lu[0][0]']         \n",
      " Dropout1D)                                                                                       \n",
      "                                                                                                  \n",
      " spatial_dropout1d_3 (Spati  (None, 32, 32)               0         ['leaky_re_lu_3[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 32)               0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 32, 16)               1536      ['spatial_dropout1d[0][0]']   \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)           (None, 32, 16)               1536      ['spatial_dropout1d_3[0][0]'] \n",
      "                                                                                                  \n",
      " spatial_dropout1d_6 (Spati  (None, 16, 32)               0         ['leaky_re_lu_6[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 32, 16)               64        ['conv1d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 32, 16)               64        ['conv1d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)           (None, 16, 16)               1536      ['spatial_dropout1d_6[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 16)               0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 16)               0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 16, 16)               64        ['conv1d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " spatial_dropout1d_1 (Spati  (None, 32, 16)               0         ['leaky_re_lu_1[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout1d_4 (Spati  (None, 32, 16)               0         ['leaky_re_lu_4[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 16, 16)               0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)           (None, 32, 16)               256       ['spatial_dropout1d_1[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)           (None, 32, 16)               256       ['spatial_dropout1d_4[0][0]'] \n",
      "                                                                                                  \n",
      " spatial_dropout1d_7 (Spati  (None, 16, 16)               0         ['leaky_re_lu_7[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 32, 16)               64        ['conv1d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 32, 16)               64        ['conv1d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)           (None, 16, 16)               256       ['spatial_dropout1d_7[0][0]'] \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 32, 16)               0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32, 16)               0         ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 16, 16)               64        ['conv1d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1  (None, 16, 16)               0         ['leaky_re_lu_2[0][0]']       \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPoolin  (None, 16, 16)               0         ['leaky_re_lu_5[0][0]']       \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16)               0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " spatial_dropout1d_2 (Spati  (None, 16, 16)               0         ['max_pooling1d[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout1d_5 (Spati  (None, 16, 16)               0         ['max_pooling1d_1[0][0]']     \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " spatial_dropout1d_8 (Spati  (None, 16, 16)               0         ['leaky_re_lu_8[0][0]']       \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 16, 48)               0         ['spatial_dropout1d_2[0][0]', \n",
      "                                                                     'spatial_dropout1d_5[0][0]', \n",
      "                                                                     'spatial_dropout1d_8[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)           (None, 16, 32)               4608      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 16, 32)               128       ['conv1d_9[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 16, 32)               0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)          (None, 16, 32)               3072      ['leaky_re_lu_9[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 16, 32)               128       ['conv1d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 16, 32)               0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPoolin  (None, 8, 32)                0         ['leaky_re_lu_10[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout1d_9 (Spati  (None, 8, 32)                0         ['max_pooling1d_2[0][0]']     \n",
      " alDropout1D)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)          (None, 8, 64)                6144      ['spatial_dropout1d_9[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 8, 64)                256       ['conv1d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 8, 64)                0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)          (None, 8, 64)                12288     ['leaky_re_lu_11[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 8, 64)                256       ['conv1d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 8, 64)                0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPoolin  (None, 4, 64)                0         ['leaky_re_lu_12[0][0]']      \n",
      " g1D)                                                                                             \n",
      "                                                                                                  \n",
      " spatial_dropout1d_10 (Spat  (None, 4, 64)                0         ['max_pooling1d_3[0][0]']     \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)          (None, 4, 128)               24576     ['spatial_dropout1d_10[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 4, 128)               512       ['conv1d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 4, 128)               0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)          (None, 4, 128)               49152     ['leaky_re_lu_13[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 4, 128)               512       ['conv1d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 4, 128)               0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " spatial_dropout1d_11 (Spat  (None, 4, 128)               0         ['leaky_re_lu_14[0][0]']      \n",
      " ialDropout1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 128)                  0         ['spatial_dropout1d_11[0][0]']\n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  16384     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 128)                  512       ['dense[0][0]']               \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['leaky_re_lu_15[0][0]']      \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  16384     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (None, 128)                  512       ['dense_1[0][0]']             \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 128)                  0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['leaky_re_lu_16[0][0]']      \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 14)                   1806      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 154990 (605.43 KB)\n",
      "Trainable params: 153198 (598.43 KB)\n",
      "Non-trainable params: 1792 (7.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DD_Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def prepare_data(filename: str):\n",
    "    data = pickle.load(open(config.data_directory + filename, \"rb\"))\n",
    "\n",
    "    Labels = []\n",
    "    Distances = []\n",
    "    Motion = []\n",
    "\n",
    "    print(f\"Preparing data from {filename}...\")\n",
    "\n",
    "    for i in tqdm(range(len(data['pose']))):\n",
    "        motion = np.copy(data['pose'][i]).reshape([-1, 22, 3])\n",
    "        motion = zoom_frames(motion, config.frame_length, config.joints_number, config.joints_dimension)\n",
    "        motion = normalize_range(motion)\n",
    "\n",
    "        label = np.zeros(config.classes_number)\n",
    "        label[data['label'][i] - 1] = 1\n",
    "\n",
    "        distance = get_joint_collection_distances(motion, config)\n",
    "\n",
    "        Distances.append(distance)\n",
    "        Motion.append(motion)\n",
    "        Labels.append(label)\n",
    "\n",
    "    Distances = np.stack(Distances)\n",
    "    Motion = np.stack(Motion)\n",
    "    Labels = np.stack(Labels)\n",
    "\n",
    "    return [Distances, Motion], Labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data from train1.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1960/1960 [00:05<00:00, 371.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data from valid1.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 840/840 [00:02<00:00, 386.70it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = prepare_data(\"train1.pkl\")\n",
    "X_valid, Y_valid = prepare_data(\"valid1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "DD_Net.compile(loss=\"categorical_crossentropy\",\n",
    "               optimizer=keras.optimizers.legacy.Adam(lr),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, X_train, Y_train, X_valid, Y_valid, epochs=100):\n",
    "    callbacks = []\n",
    "    lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                                     factor=0.5,\n",
    "                                                     patience=5,\n",
    "                                                     cooldown=5,\n",
    "                                                     min_lr=5e-6)\n",
    "    callbacks.append(lr_scheduler)\n",
    "    \n",
    "    history = model.fit(X_train,\n",
    "                        Y_train,\n",
    "                        batch_size=len(Y_train),\n",
    "                        epochs=epochs,\n",
    "                        verbose=True,\n",
    "                        shuffle=True,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=(X_valid, Y_valid)\n",
    "                        )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 04:41:57.438590: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 3.1400 - accuracy: 0.0658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 04:41:59.948320: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step - loss: 3.1400 - accuracy: 0.0658 - val_loss: 2.6390 - val_accuracy: 0.1298 - lr: 0.0010\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 2.9627 - accuracy: 0.0913 - val_loss: 2.6392 - val_accuracy: 0.0810 - lr: 0.0010\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 2.7761 - accuracy: 0.1173 - val_loss: 2.6395 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.6554 - accuracy: 0.1434 - val_loss: 2.6399 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 2.5942 - accuracy: 0.1765 - val_loss: 2.6406 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 2.5640 - accuracy: 0.1592 - val_loss: 2.6415 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 2.4866 - accuracy: 0.1714 - val_loss: 2.6425 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 2.4289 - accuracy: 0.1827 - val_loss: 2.6438 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.3575 - accuracy: 0.2082 - val_loss: 2.6452 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.2893 - accuracy: 0.2418 - val_loss: 2.6470 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 2.2518 - accuracy: 0.2423 - val_loss: 2.6492 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 2.1976 - accuracy: 0.2658 - val_loss: 2.6517 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 2.1765 - accuracy: 0.2816 - val_loss: 2.6545 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 2.1412 - accuracy: 0.2781 - val_loss: 2.6577 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 2.0460 - accuracy: 0.3148 - val_loss: 2.6613 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 1.9896 - accuracy: 0.3245 - val_loss: 2.6654 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 1.9771 - accuracy: 0.3260 - val_loss: 2.6698 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 444ms/step - loss: 1.9203 - accuracy: 0.3495 - val_loss: 2.6747 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 1.8873 - accuracy: 0.3577 - val_loss: 2.6800 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 1.8275 - accuracy: 0.3990 - val_loss: 2.6858 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 1.7728 - accuracy: 0.4179 - val_loss: 2.6922 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.7352 - accuracy: 0.4276 - val_loss: 2.6991 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.7025 - accuracy: 0.4342 - val_loss: 2.7068 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.6603 - accuracy: 0.4668 - val_loss: 2.7153 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.6214 - accuracy: 0.4709 - val_loss: 2.7248 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 1.5939 - accuracy: 0.4612 - val_loss: 2.7349 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.5362 - accuracy: 0.4918 - val_loss: 2.7460 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 1.4872 - accuracy: 0.5051 - val_loss: 2.7580 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.4238 - accuracy: 0.5541 - val_loss: 2.7712 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.3919 - accuracy: 0.5531 - val_loss: 2.7848 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.3310 - accuracy: 0.5852 - val_loss: 2.7988 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.3115 - accuracy: 0.5872 - val_loss: 2.8133 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.2776 - accuracy: 0.5913 - val_loss: 2.8275 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 1.2410 - accuracy: 0.6031 - val_loss: 2.8421 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.2100 - accuracy: 0.6189 - val_loss: 2.8571 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 1.1651 - accuracy: 0.6332 - val_loss: 2.8721 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.1447 - accuracy: 0.6459 - val_loss: 2.8881 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 1.1004 - accuracy: 0.6622 - val_loss: 2.9065 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.0961 - accuracy: 0.6551 - val_loss: 2.9263 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 1.0508 - accuracy: 0.6760 - val_loss: 2.9464 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 1.0418 - accuracy: 0.6770 - val_loss: 2.9681 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.9736 - accuracy: 0.7056 - val_loss: 2.9904 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.9559 - accuracy: 0.6990 - val_loss: 3.0130 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.9409 - accuracy: 0.7107 - val_loss: 3.0341 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.9252 - accuracy: 0.7301 - val_loss: 3.0544 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.8817 - accuracy: 0.7245 - val_loss: 3.0737 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.8792 - accuracy: 0.7036 - val_loss: 3.0903 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.8565 - accuracy: 0.7296 - val_loss: 3.1078 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.8256 - accuracy: 0.7480 - val_loss: 3.1247 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 0.8226 - accuracy: 0.7321 - val_loss: 3.1413 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.7671 - accuracy: 0.7709 - val_loss: 3.1569 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.7836 - accuracy: 0.7612 - val_loss: 3.1747 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.7348 - accuracy: 0.7806 - val_loss: 3.1948 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.7490 - accuracy: 0.7663 - val_loss: 3.2168 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.7142 - accuracy: 0.7847 - val_loss: 3.2421 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.6869 - accuracy: 0.7878 - val_loss: 3.2690 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.6711 - accuracy: 0.8000 - val_loss: 3.2975 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.6459 - accuracy: 0.8051 - val_loss: 3.3245 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.6365 - accuracy: 0.8092 - val_loss: 3.3479 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6190 - accuracy: 0.8173 - val_loss: 3.3702 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.5981 - accuracy: 0.8316 - val_loss: 3.3907 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.6075 - accuracy: 0.8224 - val_loss: 3.4071 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.5792 - accuracy: 0.8245 - val_loss: 3.4220 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.5573 - accuracy: 0.8301 - val_loss: 3.4351 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5564 - accuracy: 0.8398 - val_loss: 3.4470 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.5281 - accuracy: 0.8434 - val_loss: 3.4619 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.5314 - accuracy: 0.8423 - val_loss: 3.4824 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.5225 - accuracy: 0.8439 - val_loss: 3.5048 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.5087 - accuracy: 0.8597 - val_loss: 3.5312 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.5137 - accuracy: 0.8510 - val_loss: 3.5628 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.4640 - accuracy: 0.8633 - val_loss: 3.5946 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.4786 - accuracy: 0.8556 - val_loss: 3.6247 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.4748 - accuracy: 0.8592 - val_loss: 3.6570 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4671 - accuracy: 0.8673 - val_loss: 3.6900 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.4417 - accuracy: 0.8694 - val_loss: 3.7219 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.4093 - accuracy: 0.8862 - val_loss: 3.7487 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.4002 - accuracy: 0.8857 - val_loss: 3.7710 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.4239 - accuracy: 0.8852 - val_loss: 3.7922 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 0.3977 - accuracy: 0.8908 - val_loss: 3.8121 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.4018 - accuracy: 0.8867 - val_loss: 3.8319 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.4013 - accuracy: 0.8827 - val_loss: 3.8440 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3706 - accuracy: 0.8974 - val_loss: 3.8597 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.3868 - accuracy: 0.8796 - val_loss: 3.8787 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.3767 - accuracy: 0.8908 - val_loss: 3.9004 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.3759 - accuracy: 0.8964 - val_loss: 3.9232 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.3826 - accuracy: 0.8913 - val_loss: 3.9528 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.3533 - accuracy: 0.8939 - val_loss: 3.9793 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.3379 - accuracy: 0.9077 - val_loss: 4.0078 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.3156 - accuracy: 0.9173 - val_loss: 4.0361 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.3281 - accuracy: 0.9087 - val_loss: 4.0541 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.3213 - accuracy: 0.9143 - val_loss: 4.0712 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.3173 - accuracy: 0.9061 - val_loss: 4.0842 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.3199 - accuracy: 0.9117 - val_loss: 4.0890 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2892 - accuracy: 0.9224 - val_loss: 4.0961 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.3086 - accuracy: 0.9122 - val_loss: 4.1032 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.3009 - accuracy: 0.9107 - val_loss: 4.1180 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2846 - accuracy: 0.9219 - val_loss: 4.1285 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.2809 - accuracy: 0.9270 - val_loss: 4.1482 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.2873 - accuracy: 0.9163 - val_loss: 4.1691 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2906 - accuracy: 0.9204 - val_loss: 4.1835 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.2836 - accuracy: 0.9230 - val_loss: 4.2143 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2791 - accuracy: 0.9250 - val_loss: 4.2505 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2677 - accuracy: 0.9230 - val_loss: 4.2886 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2667 - accuracy: 0.9296 - val_loss: 4.3159 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.2506 - accuracy: 0.9276 - val_loss: 4.3399 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2534 - accuracy: 0.9230 - val_loss: 4.3606 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.2464 - accuracy: 0.9403 - val_loss: 4.3807 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.2553 - accuracy: 0.9224 - val_loss: 4.3964 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.2498 - accuracy: 0.9250 - val_loss: 4.4206 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.2293 - accuracy: 0.9342 - val_loss: 4.4319 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.2374 - accuracy: 0.9311 - val_loss: 4.4523 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.2292 - accuracy: 0.9378 - val_loss: 4.4661 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.2301 - accuracy: 0.9413 - val_loss: 4.4625 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.2166 - accuracy: 0.9444 - val_loss: 4.4506 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.2270 - accuracy: 0.9408 - val_loss: 4.4241 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.2096 - accuracy: 0.9408 - val_loss: 4.4090 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.2168 - accuracy: 0.9408 - val_loss: 4.4099 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1954 - accuracy: 0.9536 - val_loss: 4.4364 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1967 - accuracy: 0.9490 - val_loss: 4.4787 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.2042 - accuracy: 0.9449 - val_loss: 4.5379 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.2167 - accuracy: 0.9413 - val_loss: 4.6136 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1798 - accuracy: 0.9490 - val_loss: 4.6848 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1801 - accuracy: 0.9571 - val_loss: 4.7348 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1851 - accuracy: 0.9531 - val_loss: 4.7316 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1871 - accuracy: 0.9480 - val_loss: 4.6909 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1973 - accuracy: 0.9454 - val_loss: 4.6514 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1914 - accuracy: 0.9480 - val_loss: 4.6043 - val_accuracy: 0.0607 - lr: 0.0010\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1960 - accuracy: 0.9444 - val_loss: 4.5834 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1812 - accuracy: 0.9520 - val_loss: 4.5622 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1825 - accuracy: 0.9510 - val_loss: 4.5402 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1791 - accuracy: 0.9505 - val_loss: 4.5168 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1839 - accuracy: 0.9515 - val_loss: 4.4941 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.1655 - accuracy: 0.9536 - val_loss: 4.4797 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1717 - accuracy: 0.9612 - val_loss: 4.4613 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1725 - accuracy: 0.9541 - val_loss: 4.4466 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1737 - accuracy: 0.9495 - val_loss: 4.4389 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1804 - accuracy: 0.9520 - val_loss: 4.4261 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1692 - accuracy: 0.9520 - val_loss: 4.4177 - val_accuracy: 0.0607 - lr: 5.0000e-04\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1547 - accuracy: 0.9602 - val_loss: 4.4166 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1649 - accuracy: 0.9536 - val_loss: 4.4167 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.1698 - accuracy: 0.9607 - val_loss: 4.4171 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1572 - accuracy: 0.9622 - val_loss: 4.4176 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1610 - accuracy: 0.9582 - val_loss: 4.4176 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1701 - accuracy: 0.9541 - val_loss: 4.4167 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1545 - accuracy: 0.9587 - val_loss: 4.4132 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1480 - accuracy: 0.9648 - val_loss: 4.4081 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1580 - accuracy: 0.9587 - val_loss: 4.4073 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1564 - accuracy: 0.9582 - val_loss: 4.4080 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1619 - accuracy: 0.9566 - val_loss: 4.4029 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1561 - accuracy: 0.9582 - val_loss: 4.3935 - val_accuracy: 0.0607 - lr: 2.5000e-04\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1587 - accuracy: 0.9541 - val_loss: 4.3853 - val_accuracy: 0.0619 - lr: 2.5000e-04\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1495 - accuracy: 0.9582 - val_loss: 4.3799 - val_accuracy: 0.0619 - lr: 1.2500e-04\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1511 - accuracy: 0.9607 - val_loss: 4.3756 - val_accuracy: 0.0619 - lr: 1.2500e-04\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1487 - accuracy: 0.9592 - val_loss: 4.3718 - val_accuracy: 0.0631 - lr: 1.2500e-04\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1566 - accuracy: 0.9628 - val_loss: 4.3675 - val_accuracy: 0.0631 - lr: 1.2500e-04\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.1581 - accuracy: 0.9587 - val_loss: 4.3649 - val_accuracy: 0.0643 - lr: 1.2500e-04\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1461 - accuracy: 0.9638 - val_loss: 4.3612 - val_accuracy: 0.0643 - lr: 1.2500e-04\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1516 - accuracy: 0.9638 - val_loss: 4.3568 - val_accuracy: 0.0643 - lr: 1.2500e-04\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1588 - accuracy: 0.9566 - val_loss: 4.3525 - val_accuracy: 0.0643 - lr: 1.2500e-04\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1456 - accuracy: 0.9648 - val_loss: 4.3452 - val_accuracy: 0.0655 - lr: 1.2500e-04\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1620 - accuracy: 0.9505 - val_loss: 4.3386 - val_accuracy: 0.0655 - lr: 1.2500e-04\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 0.1695 - accuracy: 0.9571 - val_loss: 4.3300 - val_accuracy: 0.0667 - lr: 1.2500e-04\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1631 - accuracy: 0.9582 - val_loss: 4.3179 - val_accuracy: 0.0679 - lr: 1.2500e-04\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1816 - accuracy: 0.9515 - val_loss: 4.3045 - val_accuracy: 0.0679 - lr: 1.2500e-04\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1511 - accuracy: 0.9633 - val_loss: 4.2916 - val_accuracy: 0.0679 - lr: 1.2500e-04\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1493 - accuracy: 0.9617 - val_loss: 4.2798 - val_accuracy: 0.0679 - lr: 6.2500e-05\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 4.2673 - val_accuracy: 0.0690 - lr: 6.2500e-05\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1618 - accuracy: 0.9592 - val_loss: 4.2554 - val_accuracy: 0.0690 - lr: 6.2500e-05\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1536 - accuracy: 0.9622 - val_loss: 4.2426 - val_accuracy: 0.0690 - lr: 6.2500e-05\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1578 - accuracy: 0.9587 - val_loss: 4.2315 - val_accuracy: 0.0690 - lr: 6.2500e-05\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1560 - accuracy: 0.9587 - val_loss: 4.2207 - val_accuracy: 0.0702 - lr: 6.2500e-05\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1460 - accuracy: 0.9628 - val_loss: 4.2088 - val_accuracy: 0.0702 - lr: 6.2500e-05\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1605 - accuracy: 0.9571 - val_loss: 4.1964 - val_accuracy: 0.0702 - lr: 6.2500e-05\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 4.1833 - val_accuracy: 0.0738 - lr: 6.2500e-05\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1643 - accuracy: 0.9592 - val_loss: 4.1708 - val_accuracy: 0.0738 - lr: 3.1250e-05\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1571 - accuracy: 0.9566 - val_loss: 4.1584 - val_accuracy: 0.0762 - lr: 3.1250e-05\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1441 - accuracy: 0.9582 - val_loss: 4.1456 - val_accuracy: 0.0774 - lr: 3.1250e-05\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1461 - accuracy: 0.9622 - val_loss: 4.1335 - val_accuracy: 0.0786 - lr: 3.1250e-05\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1456 - accuracy: 0.9587 - val_loss: 4.1213 - val_accuracy: 0.0821 - lr: 3.1250e-05\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1478 - accuracy: 0.9607 - val_loss: 4.1100 - val_accuracy: 0.0821 - lr: 3.1250e-05\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1526 - accuracy: 0.9633 - val_loss: 4.0982 - val_accuracy: 0.0833 - lr: 3.1250e-05\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1513 - accuracy: 0.9597 - val_loss: 4.0869 - val_accuracy: 0.0833 - lr: 3.1250e-05\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1771 - accuracy: 0.9577 - val_loss: 4.0741 - val_accuracy: 0.0845 - lr: 3.1250e-05\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1416 - accuracy: 0.9628 - val_loss: 4.0614 - val_accuracy: 0.0857 - lr: 1.5625e-05\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1490 - accuracy: 0.9633 - val_loss: 4.0485 - val_accuracy: 0.0857 - lr: 1.5625e-05\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1603 - accuracy: 0.9612 - val_loss: 4.0356 - val_accuracy: 0.0857 - lr: 1.5625e-05\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1515 - accuracy: 0.9612 - val_loss: 4.0224 - val_accuracy: 0.0881 - lr: 1.5625e-05\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1439 - accuracy: 0.9668 - val_loss: 4.0096 - val_accuracy: 0.0893 - lr: 1.5625e-05\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1438 - accuracy: 0.9607 - val_loss: 3.9967 - val_accuracy: 0.0893 - lr: 1.5625e-05\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 0.1523 - accuracy: 0.9592 - val_loss: 3.9840 - val_accuracy: 0.0917 - lr: 1.5625e-05\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1566 - accuracy: 0.9490 - val_loss: 3.9711 - val_accuracy: 0.0929 - lr: 1.5625e-05\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1427 - accuracy: 0.9628 - val_loss: 3.9581 - val_accuracy: 0.0929 - lr: 1.5625e-05\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1584 - accuracy: 0.9577 - val_loss: 3.9447 - val_accuracy: 0.0929 - lr: 7.8125e-06\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1492 - accuracy: 0.9617 - val_loss: 3.9310 - val_accuracy: 0.0952 - lr: 7.8125e-06\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1414 - accuracy: 0.9653 - val_loss: 3.9171 - val_accuracy: 0.0952 - lr: 7.8125e-06\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1623 - accuracy: 0.9592 - val_loss: 3.9027 - val_accuracy: 0.0964 - lr: 7.8125e-06\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1447 - accuracy: 0.9638 - val_loss: 3.8885 - val_accuracy: 0.0976 - lr: 7.8125e-06\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1419 - accuracy: 0.9628 - val_loss: 3.8744 - val_accuracy: 0.0976 - lr: 7.8125e-06\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1340 - accuracy: 0.9679 - val_loss: 3.8608 - val_accuracy: 0.1012 - lr: 7.8125e-06\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1489 - accuracy: 0.9582 - val_loss: 3.8469 - val_accuracy: 0.1036 - lr: 7.8125e-06\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1432 - accuracy: 0.9663 - val_loss: 3.8333 - val_accuracy: 0.1071 - lr: 7.8125e-06\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.1401 - accuracy: 0.9628 - val_loss: 3.8202 - val_accuracy: 0.1095 - lr: 7.8125e-06\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1484 - accuracy: 0.9582 - val_loss: 3.8061 - val_accuracy: 0.1131 - lr: 7.8125e-06\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1501 - accuracy: 0.9612 - val_loss: 3.7921 - val_accuracy: 0.1143 - lr: 7.8125e-06\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1567 - accuracy: 0.9617 - val_loss: 3.7781 - val_accuracy: 0.1143 - lr: 5.0000e-06\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1491 - accuracy: 0.9643 - val_loss: 3.7635 - val_accuracy: 0.1179 - lr: 5.0000e-06\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1553 - accuracy: 0.9587 - val_loss: 3.7490 - val_accuracy: 0.1179 - lr: 5.0000e-06\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1487 - accuracy: 0.9628 - val_loss: 3.7344 - val_accuracy: 0.1179 - lr: 5.0000e-06\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1443 - accuracy: 0.9704 - val_loss: 3.7196 - val_accuracy: 0.1202 - lr: 5.0000e-06\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1571 - accuracy: 0.9607 - val_loss: 3.7051 - val_accuracy: 0.1262 - lr: 5.0000e-06\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1571 - accuracy: 0.9577 - val_loss: 3.6903 - val_accuracy: 0.1286 - lr: 5.0000e-06\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1420 - accuracy: 0.9658 - val_loss: 3.6751 - val_accuracy: 0.1298 - lr: 5.0000e-06\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1519 - accuracy: 0.9628 - val_loss: 3.6598 - val_accuracy: 0.1310 - lr: 5.0000e-06\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1420 - accuracy: 0.9622 - val_loss: 3.6443 - val_accuracy: 0.1345 - lr: 5.0000e-06\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1538 - accuracy: 0.9566 - val_loss: 3.6291 - val_accuracy: 0.1393 - lr: 5.0000e-06\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1573 - accuracy: 0.9571 - val_loss: 3.6138 - val_accuracy: 0.1429 - lr: 5.0000e-06\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1371 - accuracy: 0.9668 - val_loss: 3.5981 - val_accuracy: 0.1464 - lr: 5.0000e-06\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1563 - accuracy: 0.9612 - val_loss: 3.5823 - val_accuracy: 0.1476 - lr: 5.0000e-06\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1533 - accuracy: 0.9571 - val_loss: 3.5672 - val_accuracy: 0.1476 - lr: 5.0000e-06\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1636 - accuracy: 0.9582 - val_loss: 3.5511 - val_accuracy: 0.1500 - lr: 5.0000e-06\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1680 - accuracy: 0.9551 - val_loss: 3.5349 - val_accuracy: 0.1512 - lr: 5.0000e-06\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1570 - accuracy: 0.9612 - val_loss: 3.5187 - val_accuracy: 0.1524 - lr: 5.0000e-06\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1423 - accuracy: 0.9699 - val_loss: 3.5028 - val_accuracy: 0.1560 - lr: 5.0000e-06\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1460 - accuracy: 0.9653 - val_loss: 3.4866 - val_accuracy: 0.1595 - lr: 5.0000e-06\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1604 - accuracy: 0.9541 - val_loss: 3.4703 - val_accuracy: 0.1607 - lr: 5.0000e-06\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1540 - accuracy: 0.9602 - val_loss: 3.4535 - val_accuracy: 0.1607 - lr: 5.0000e-06\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1429 - accuracy: 0.9638 - val_loss: 3.4364 - val_accuracy: 0.1643 - lr: 5.0000e-06\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1494 - accuracy: 0.9566 - val_loss: 3.4196 - val_accuracy: 0.1655 - lr: 5.0000e-06\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1482 - accuracy: 0.9638 - val_loss: 3.4027 - val_accuracy: 0.1667 - lr: 5.0000e-06\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1512 - accuracy: 0.9643 - val_loss: 3.3857 - val_accuracy: 0.1679 - lr: 5.0000e-06\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1489 - accuracy: 0.9658 - val_loss: 3.3689 - val_accuracy: 0.1690 - lr: 5.0000e-06\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1423 - accuracy: 0.9648 - val_loss: 3.3522 - val_accuracy: 0.1702 - lr: 5.0000e-06\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1536 - accuracy: 0.9571 - val_loss: 3.3355 - val_accuracy: 0.1726 - lr: 5.0000e-06\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1458 - accuracy: 0.9638 - val_loss: 3.3184 - val_accuracy: 0.1774 - lr: 5.0000e-06\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1552 - accuracy: 0.9587 - val_loss: 3.3013 - val_accuracy: 0.1786 - lr: 5.0000e-06\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1438 - accuracy: 0.9638 - val_loss: 3.2841 - val_accuracy: 0.1821 - lr: 5.0000e-06\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1507 - accuracy: 0.9597 - val_loss: 3.2679 - val_accuracy: 0.1857 - lr: 5.0000e-06\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1503 - accuracy: 0.9628 - val_loss: 3.2508 - val_accuracy: 0.1881 - lr: 5.0000e-06\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1391 - accuracy: 0.9612 - val_loss: 3.2339 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1426 - accuracy: 0.9684 - val_loss: 3.2166 - val_accuracy: 0.1893 - lr: 5.0000e-06\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1731 - accuracy: 0.9510 - val_loss: 3.1996 - val_accuracy: 0.1905 - lr: 5.0000e-06\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1505 - accuracy: 0.9628 - val_loss: 3.1823 - val_accuracy: 0.1940 - lr: 5.0000e-06\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1451 - accuracy: 0.9597 - val_loss: 3.1647 - val_accuracy: 0.1988 - lr: 5.0000e-06\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1584 - accuracy: 0.9628 - val_loss: 3.1475 - val_accuracy: 0.2012 - lr: 5.0000e-06\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1401 - accuracy: 0.9648 - val_loss: 3.1308 - val_accuracy: 0.2036 - lr: 5.0000e-06\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1561 - accuracy: 0.9612 - val_loss: 3.1137 - val_accuracy: 0.2071 - lr: 5.0000e-06\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1502 - accuracy: 0.9638 - val_loss: 3.0965 - val_accuracy: 0.2071 - lr: 5.0000e-06\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1507 - accuracy: 0.9597 - val_loss: 3.0794 - val_accuracy: 0.2083 - lr: 5.0000e-06\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1456 - accuracy: 0.9577 - val_loss: 3.0618 - val_accuracy: 0.2107 - lr: 5.0000e-06\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1521 - accuracy: 0.9577 - val_loss: 3.0445 - val_accuracy: 0.2119 - lr: 5.0000e-06\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1500 - accuracy: 0.9628 - val_loss: 3.0273 - val_accuracy: 0.2119 - lr: 5.0000e-06\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1471 - accuracy: 0.9612 - val_loss: 3.0096 - val_accuracy: 0.2155 - lr: 5.0000e-06\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.1454 - accuracy: 0.9633 - val_loss: 2.9924 - val_accuracy: 0.2167 - lr: 5.0000e-06\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1572 - accuracy: 0.9577 - val_loss: 2.9750 - val_accuracy: 0.2202 - lr: 5.0000e-06\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1587 - accuracy: 0.9582 - val_loss: 2.9576 - val_accuracy: 0.2262 - lr: 5.0000e-06\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1467 - accuracy: 0.9607 - val_loss: 2.9404 - val_accuracy: 0.2286 - lr: 5.0000e-06\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1518 - accuracy: 0.9628 - val_loss: 2.9228 - val_accuracy: 0.2345 - lr: 5.0000e-06\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1501 - accuracy: 0.9607 - val_loss: 2.9052 - val_accuracy: 0.2357 - lr: 5.0000e-06\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1431 - accuracy: 0.9658 - val_loss: 2.8874 - val_accuracy: 0.2357 - lr: 5.0000e-06\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1427 - accuracy: 0.9673 - val_loss: 2.8700 - val_accuracy: 0.2393 - lr: 5.0000e-06\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1659 - accuracy: 0.9582 - val_loss: 2.8525 - val_accuracy: 0.2417 - lr: 5.0000e-06\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1452 - accuracy: 0.9607 - val_loss: 2.8351 - val_accuracy: 0.2417 - lr: 5.0000e-06\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1533 - accuracy: 0.9592 - val_loss: 2.8180 - val_accuracy: 0.2464 - lr: 5.0000e-06\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1608 - accuracy: 0.9541 - val_loss: 2.8009 - val_accuracy: 0.2476 - lr: 5.0000e-06\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1493 - accuracy: 0.9612 - val_loss: 2.7837 - val_accuracy: 0.2500 - lr: 5.0000e-06\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1396 - accuracy: 0.9653 - val_loss: 2.7669 - val_accuracy: 0.2560 - lr: 5.0000e-06\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1473 - accuracy: 0.9643 - val_loss: 2.7498 - val_accuracy: 0.2595 - lr: 5.0000e-06\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1482 - accuracy: 0.9622 - val_loss: 2.7326 - val_accuracy: 0.2631 - lr: 5.0000e-06\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1518 - accuracy: 0.9658 - val_loss: 2.7157 - val_accuracy: 0.2655 - lr: 5.0000e-06\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1400 - accuracy: 0.9668 - val_loss: 2.6990 - val_accuracy: 0.2702 - lr: 5.0000e-06\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1371 - accuracy: 0.9684 - val_loss: 2.6824 - val_accuracy: 0.2726 - lr: 5.0000e-06\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1526 - accuracy: 0.9577 - val_loss: 2.6654 - val_accuracy: 0.2762 - lr: 5.0000e-06\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1474 - accuracy: 0.9643 - val_loss: 2.6488 - val_accuracy: 0.2821 - lr: 5.0000e-06\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1505 - accuracy: 0.9638 - val_loss: 2.6318 - val_accuracy: 0.2881 - lr: 5.0000e-06\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1501 - accuracy: 0.9607 - val_loss: 2.6150 - val_accuracy: 0.2881 - lr: 5.0000e-06\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1440 - accuracy: 0.9597 - val_loss: 2.5982 - val_accuracy: 0.2940 - lr: 5.0000e-06\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1394 - accuracy: 0.9684 - val_loss: 2.5811 - val_accuracy: 0.3000 - lr: 5.0000e-06\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1593 - accuracy: 0.9546 - val_loss: 2.5646 - val_accuracy: 0.3083 - lr: 5.0000e-06\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1428 - accuracy: 0.9592 - val_loss: 2.5476 - val_accuracy: 0.3131 - lr: 5.0000e-06\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 360ms/step - loss: 0.1325 - accuracy: 0.9653 - val_loss: 2.5308 - val_accuracy: 0.3167 - lr: 5.0000e-06\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 0.1467 - accuracy: 0.9622 - val_loss: 2.5140 - val_accuracy: 0.3214 - lr: 5.0000e-06\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1444 - accuracy: 0.9612 - val_loss: 2.4971 - val_accuracy: 0.3250 - lr: 5.0000e-06\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1551 - accuracy: 0.9622 - val_loss: 2.4801 - val_accuracy: 0.3274 - lr: 5.0000e-06\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1582 - accuracy: 0.9531 - val_loss: 2.4632 - val_accuracy: 0.3298 - lr: 5.0000e-06\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1598 - accuracy: 0.9536 - val_loss: 2.4466 - val_accuracy: 0.3357 - lr: 5.0000e-06\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1404 - accuracy: 0.9648 - val_loss: 2.4297 - val_accuracy: 0.3357 - lr: 5.0000e-06\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1433 - accuracy: 0.9689 - val_loss: 2.4129 - val_accuracy: 0.3393 - lr: 5.0000e-06\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1402 - accuracy: 0.9633 - val_loss: 2.3966 - val_accuracy: 0.3429 - lr: 5.0000e-06\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1469 - accuracy: 0.9587 - val_loss: 2.3806 - val_accuracy: 0.3476 - lr: 5.0000e-06\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1653 - accuracy: 0.9597 - val_loss: 2.3639 - val_accuracy: 0.3512 - lr: 5.0000e-06\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1534 - accuracy: 0.9628 - val_loss: 2.3476 - val_accuracy: 0.3524 - lr: 5.0000e-06\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1337 - accuracy: 0.9699 - val_loss: 2.3316 - val_accuracy: 0.3571 - lr: 5.0000e-06\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1464 - accuracy: 0.9638 - val_loss: 2.3157 - val_accuracy: 0.3595 - lr: 5.0000e-06\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1448 - accuracy: 0.9689 - val_loss: 2.3002 - val_accuracy: 0.3655 - lr: 5.0000e-06\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1588 - accuracy: 0.9577 - val_loss: 2.2841 - val_accuracy: 0.3690 - lr: 5.0000e-06\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1414 - accuracy: 0.9638 - val_loss: 2.2679 - val_accuracy: 0.3738 - lr: 5.0000e-06\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1489 - accuracy: 0.9633 - val_loss: 2.2520 - val_accuracy: 0.3762 - lr: 5.0000e-06\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1609 - accuracy: 0.9551 - val_loss: 2.2365 - val_accuracy: 0.3857 - lr: 5.0000e-06\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1588 - accuracy: 0.9582 - val_loss: 2.2208 - val_accuracy: 0.3869 - lr: 5.0000e-06\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1456 - accuracy: 0.9663 - val_loss: 2.2056 - val_accuracy: 0.3893 - lr: 5.0000e-06\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1467 - accuracy: 0.9592 - val_loss: 2.1902 - val_accuracy: 0.3964 - lr: 5.0000e-06\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1511 - accuracy: 0.9612 - val_loss: 2.1745 - val_accuracy: 0.4012 - lr: 5.0000e-06\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1385 - accuracy: 0.9617 - val_loss: 2.1595 - val_accuracy: 0.4024 - lr: 5.0000e-06\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1431 - accuracy: 0.9668 - val_loss: 2.1440 - val_accuracy: 0.4071 - lr: 5.0000e-06\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1574 - accuracy: 0.9597 - val_loss: 2.1286 - val_accuracy: 0.4107 - lr: 5.0000e-06\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1530 - accuracy: 0.9597 - val_loss: 2.1138 - val_accuracy: 0.4179 - lr: 5.0000e-06\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1596 - accuracy: 0.9582 - val_loss: 2.0986 - val_accuracy: 0.4214 - lr: 5.0000e-06\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1552 - accuracy: 0.9592 - val_loss: 2.0837 - val_accuracy: 0.4226 - lr: 5.0000e-06\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1530 - accuracy: 0.9638 - val_loss: 2.0686 - val_accuracy: 0.4274 - lr: 5.0000e-06\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1525 - accuracy: 0.9643 - val_loss: 2.0535 - val_accuracy: 0.4310 - lr: 5.0000e-06\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1555 - accuracy: 0.9566 - val_loss: 2.0383 - val_accuracy: 0.4345 - lr: 5.0000e-06\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1395 - accuracy: 0.9648 - val_loss: 2.0238 - val_accuracy: 0.4381 - lr: 5.0000e-06\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1382 - accuracy: 0.9653 - val_loss: 2.0093 - val_accuracy: 0.4440 - lr: 5.0000e-06\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1527 - accuracy: 0.9587 - val_loss: 1.9947 - val_accuracy: 0.4440 - lr: 5.0000e-06\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1486 - accuracy: 0.9577 - val_loss: 1.9800 - val_accuracy: 0.4476 - lr: 5.0000e-06\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1384 - accuracy: 0.9658 - val_loss: 1.9656 - val_accuracy: 0.4488 - lr: 5.0000e-06\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1435 - accuracy: 0.9622 - val_loss: 1.9513 - val_accuracy: 0.4548 - lr: 5.0000e-06\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1366 - accuracy: 0.9628 - val_loss: 1.9371 - val_accuracy: 0.4583 - lr: 5.0000e-06\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1512 - accuracy: 0.9571 - val_loss: 1.9229 - val_accuracy: 0.4655 - lr: 5.0000e-06\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1523 - accuracy: 0.9628 - val_loss: 1.9086 - val_accuracy: 0.4667 - lr: 5.0000e-06\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1351 - accuracy: 0.9673 - val_loss: 1.8944 - val_accuracy: 0.4690 - lr: 5.0000e-06\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1533 - accuracy: 0.9633 - val_loss: 1.8806 - val_accuracy: 0.4690 - lr: 5.0000e-06\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1589 - accuracy: 0.9571 - val_loss: 1.8665 - val_accuracy: 0.4738 - lr: 5.0000e-06\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1568 - accuracy: 0.9648 - val_loss: 1.8526 - val_accuracy: 0.4821 - lr: 5.0000e-06\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1445 - accuracy: 0.9663 - val_loss: 1.8389 - val_accuracy: 0.4881 - lr: 5.0000e-06\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1490 - accuracy: 0.9628 - val_loss: 1.8252 - val_accuracy: 0.4893 - lr: 5.0000e-06\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1526 - accuracy: 0.9638 - val_loss: 1.8114 - val_accuracy: 0.4917 - lr: 5.0000e-06\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1435 - accuracy: 0.9622 - val_loss: 1.7976 - val_accuracy: 0.4917 - lr: 5.0000e-06\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1617 - accuracy: 0.9566 - val_loss: 1.7836 - val_accuracy: 0.4929 - lr: 5.0000e-06\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1403 - accuracy: 0.9653 - val_loss: 1.7698 - val_accuracy: 0.4964 - lr: 5.0000e-06\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1565 - accuracy: 0.9617 - val_loss: 1.7565 - val_accuracy: 0.4988 - lr: 5.0000e-06\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1399 - accuracy: 0.9648 - val_loss: 1.7428 - val_accuracy: 0.5012 - lr: 5.0000e-06\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1389 - accuracy: 0.9699 - val_loss: 1.7297 - val_accuracy: 0.5048 - lr: 5.0000e-06\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1460 - accuracy: 0.9633 - val_loss: 1.7165 - val_accuracy: 0.5083 - lr: 5.0000e-06\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1441 - accuracy: 0.9653 - val_loss: 1.7035 - val_accuracy: 0.5083 - lr: 5.0000e-06\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1601 - accuracy: 0.9556 - val_loss: 1.6902 - val_accuracy: 0.5107 - lr: 5.0000e-06\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1471 - accuracy: 0.9658 - val_loss: 1.6769 - val_accuracy: 0.5119 - lr: 5.0000e-06\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1474 - accuracy: 0.9628 - val_loss: 1.6639 - val_accuracy: 0.5155 - lr: 5.0000e-06\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1416 - accuracy: 0.9684 - val_loss: 1.6510 - val_accuracy: 0.5179 - lr: 5.0000e-06\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1456 - accuracy: 0.9628 - val_loss: 1.6380 - val_accuracy: 0.5190 - lr: 5.0000e-06\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1412 - accuracy: 0.9628 - val_loss: 1.6253 - val_accuracy: 0.5238 - lr: 5.0000e-06\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1344 - accuracy: 0.9679 - val_loss: 1.6128 - val_accuracy: 0.5238 - lr: 5.0000e-06\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1522 - accuracy: 0.9628 - val_loss: 1.6003 - val_accuracy: 0.5286 - lr: 5.0000e-06\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1351 - accuracy: 0.9648 - val_loss: 1.5876 - val_accuracy: 0.5321 - lr: 5.0000e-06\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1525 - accuracy: 0.9643 - val_loss: 1.5750 - val_accuracy: 0.5333 - lr: 5.0000e-06\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1369 - accuracy: 0.9679 - val_loss: 1.5623 - val_accuracy: 0.5381 - lr: 5.0000e-06\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1434 - accuracy: 0.9648 - val_loss: 1.5497 - val_accuracy: 0.5417 - lr: 5.0000e-06\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1545 - accuracy: 0.9561 - val_loss: 1.5374 - val_accuracy: 0.5452 - lr: 5.0000e-06\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 0.1449 - accuracy: 0.9643 - val_loss: 1.5253 - val_accuracy: 0.5500 - lr: 5.0000e-06\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1341 - accuracy: 0.9668 - val_loss: 1.5127 - val_accuracy: 0.5512 - lr: 5.0000e-06\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1372 - accuracy: 0.9668 - val_loss: 1.5005 - val_accuracy: 0.5536 - lr: 5.0000e-06\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1546 - accuracy: 0.9577 - val_loss: 1.4883 - val_accuracy: 0.5548 - lr: 5.0000e-06\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1434 - accuracy: 0.9679 - val_loss: 1.4759 - val_accuracy: 0.5583 - lr: 5.0000e-06\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1474 - accuracy: 0.9638 - val_loss: 1.4641 - val_accuracy: 0.5607 - lr: 5.0000e-06\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1489 - accuracy: 0.9638 - val_loss: 1.4519 - val_accuracy: 0.5679 - lr: 5.0000e-06\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1541 - accuracy: 0.9617 - val_loss: 1.4399 - val_accuracy: 0.5738 - lr: 5.0000e-06\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1462 - accuracy: 0.9638 - val_loss: 1.4281 - val_accuracy: 0.5786 - lr: 5.0000e-06\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1261 - accuracy: 0.9730 - val_loss: 1.4162 - val_accuracy: 0.5798 - lr: 5.0000e-06\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1557 - accuracy: 0.9633 - val_loss: 1.4043 - val_accuracy: 0.5845 - lr: 5.0000e-06\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1357 - accuracy: 0.9648 - val_loss: 1.3924 - val_accuracy: 0.5881 - lr: 5.0000e-06\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1580 - accuracy: 0.9602 - val_loss: 1.3808 - val_accuracy: 0.5905 - lr: 5.0000e-06\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1354 - accuracy: 0.9679 - val_loss: 1.3692 - val_accuracy: 0.5940 - lr: 5.0000e-06\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1601 - accuracy: 0.9556 - val_loss: 1.3579 - val_accuracy: 0.5976 - lr: 5.0000e-06\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1456 - accuracy: 0.9587 - val_loss: 1.3466 - val_accuracy: 0.6012 - lr: 5.0000e-06\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1472 - accuracy: 0.9612 - val_loss: 1.3351 - val_accuracy: 0.6048 - lr: 5.0000e-06\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1381 - accuracy: 0.9643 - val_loss: 1.3241 - val_accuracy: 0.6071 - lr: 5.0000e-06\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1531 - accuracy: 0.9628 - val_loss: 1.3129 - val_accuracy: 0.6119 - lr: 5.0000e-06\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1565 - accuracy: 0.9592 - val_loss: 1.3019 - val_accuracy: 0.6155 - lr: 5.0000e-06\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1441 - accuracy: 0.9653 - val_loss: 1.2908 - val_accuracy: 0.6190 - lr: 5.0000e-06\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1424 - accuracy: 0.9679 - val_loss: 1.2797 - val_accuracy: 0.6214 - lr: 5.0000e-06\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1432 - accuracy: 0.9622 - val_loss: 1.2690 - val_accuracy: 0.6238 - lr: 5.0000e-06\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.1486 - accuracy: 0.9643 - val_loss: 1.2581 - val_accuracy: 0.6238 - lr: 5.0000e-06\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1541 - accuracy: 0.9566 - val_loss: 1.2473 - val_accuracy: 0.6250 - lr: 5.0000e-06\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1427 - accuracy: 0.9684 - val_loss: 1.2363 - val_accuracy: 0.6262 - lr: 5.0000e-06\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1377 - accuracy: 0.9582 - val_loss: 1.2257 - val_accuracy: 0.6298 - lr: 5.0000e-06\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1578 - accuracy: 0.9551 - val_loss: 1.2150 - val_accuracy: 0.6357 - lr: 5.0000e-06\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1443 - accuracy: 0.9638 - val_loss: 1.2044 - val_accuracy: 0.6381 - lr: 5.0000e-06\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1551 - accuracy: 0.9612 - val_loss: 1.1938 - val_accuracy: 0.6417 - lr: 5.0000e-06\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.1529 - accuracy: 0.9622 - val_loss: 1.1832 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 0.1461 - accuracy: 0.9617 - val_loss: 1.1727 - val_accuracy: 0.6429 - lr: 5.0000e-06\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1456 - accuracy: 0.9633 - val_loss: 1.1623 - val_accuracy: 0.6488 - lr: 5.0000e-06\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1463 - accuracy: 0.9628 - val_loss: 1.1521 - val_accuracy: 0.6512 - lr: 5.0000e-06\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1449 - accuracy: 0.9638 - val_loss: 1.1420 - val_accuracy: 0.6560 - lr: 5.0000e-06\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1409 - accuracy: 0.9663 - val_loss: 1.1319 - val_accuracy: 0.6595 - lr: 5.0000e-06\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1571 - accuracy: 0.9571 - val_loss: 1.1219 - val_accuracy: 0.6643 - lr: 5.0000e-06\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1456 - accuracy: 0.9592 - val_loss: 1.1119 - val_accuracy: 0.6667 - lr: 5.0000e-06\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1530 - accuracy: 0.9653 - val_loss: 1.1022 - val_accuracy: 0.6702 - lr: 5.0000e-06\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1445 - accuracy: 0.9658 - val_loss: 1.0924 - val_accuracy: 0.6738 - lr: 5.0000e-06\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1467 - accuracy: 0.9638 - val_loss: 1.0829 - val_accuracy: 0.6750 - lr: 5.0000e-06\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1428 - accuracy: 0.9633 - val_loss: 1.0733 - val_accuracy: 0.6786 - lr: 5.0000e-06\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1454 - accuracy: 0.9638 - val_loss: 1.0638 - val_accuracy: 0.6774 - lr: 5.0000e-06\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1512 - accuracy: 0.9622 - val_loss: 1.0545 - val_accuracy: 0.6821 - lr: 5.0000e-06\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1411 - accuracy: 0.9704 - val_loss: 1.0451 - val_accuracy: 0.6845 - lr: 5.0000e-06\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1642 - accuracy: 0.9602 - val_loss: 1.0359 - val_accuracy: 0.6857 - lr: 5.0000e-06\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1405 - accuracy: 0.9663 - val_loss: 1.0267 - val_accuracy: 0.6893 - lr: 5.0000e-06\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1430 - accuracy: 0.9607 - val_loss: 1.0177 - val_accuracy: 0.6905 - lr: 5.0000e-06\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1479 - accuracy: 0.9668 - val_loss: 1.0087 - val_accuracy: 0.6929 - lr: 5.0000e-06\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1442 - accuracy: 0.9663 - val_loss: 0.9996 - val_accuracy: 0.6976 - lr: 5.0000e-06\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1373 - accuracy: 0.9648 - val_loss: 0.9906 - val_accuracy: 0.6964 - lr: 5.0000e-06\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1584 - accuracy: 0.9602 - val_loss: 0.9817 - val_accuracy: 0.6976 - lr: 5.0000e-06\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1433 - accuracy: 0.9607 - val_loss: 0.9730 - val_accuracy: 0.7012 - lr: 5.0000e-06\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1496 - accuracy: 0.9633 - val_loss: 0.9645 - val_accuracy: 0.7036 - lr: 5.0000e-06\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1514 - accuracy: 0.9643 - val_loss: 0.9560 - val_accuracy: 0.7036 - lr: 5.0000e-06\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1407 - accuracy: 0.9612 - val_loss: 0.9475 - val_accuracy: 0.7071 - lr: 5.0000e-06\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1484 - accuracy: 0.9633 - val_loss: 0.9392 - val_accuracy: 0.7083 - lr: 5.0000e-06\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.1589 - accuracy: 0.9597 - val_loss: 0.9308 - val_accuracy: 0.7119 - lr: 5.0000e-06\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1413 - accuracy: 0.9653 - val_loss: 0.9227 - val_accuracy: 0.7143 - lr: 5.0000e-06\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1746 - accuracy: 0.9459 - val_loss: 0.9149 - val_accuracy: 0.7155 - lr: 5.0000e-06\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1599 - accuracy: 0.9587 - val_loss: 0.9069 - val_accuracy: 0.7190 - lr: 5.0000e-06\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1375 - accuracy: 0.9643 - val_loss: 0.8990 - val_accuracy: 0.7214 - lr: 5.0000e-06\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1518 - accuracy: 0.9597 - val_loss: 0.8913 - val_accuracy: 0.7250 - lr: 5.0000e-06\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1542 - accuracy: 0.9602 - val_loss: 0.8836 - val_accuracy: 0.7250 - lr: 5.0000e-06\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1499 - accuracy: 0.9602 - val_loss: 0.8762 - val_accuracy: 0.7250 - lr: 5.0000e-06\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1589 - accuracy: 0.9582 - val_loss: 0.8689 - val_accuracy: 0.7286 - lr: 5.0000e-06\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1453 - accuracy: 0.9679 - val_loss: 0.8614 - val_accuracy: 0.7298 - lr: 5.0000e-06\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 0.1491 - accuracy: 0.9663 - val_loss: 0.8539 - val_accuracy: 0.7321 - lr: 5.0000e-06\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1408 - accuracy: 0.9648 - val_loss: 0.8466 - val_accuracy: 0.7357 - lr: 5.0000e-06\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1412 - accuracy: 0.9658 - val_loss: 0.8395 - val_accuracy: 0.7369 - lr: 5.0000e-06\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1427 - accuracy: 0.9622 - val_loss: 0.8324 - val_accuracy: 0.7381 - lr: 5.0000e-06\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1297 - accuracy: 0.9699 - val_loss: 0.8254 - val_accuracy: 0.7405 - lr: 5.0000e-06\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1582 - accuracy: 0.9536 - val_loss: 0.8184 - val_accuracy: 0.7429 - lr: 5.0000e-06\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1495 - accuracy: 0.9643 - val_loss: 0.8115 - val_accuracy: 0.7452 - lr: 5.0000e-06\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1566 - accuracy: 0.9592 - val_loss: 0.8045 - val_accuracy: 0.7476 - lr: 5.0000e-06\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1306 - accuracy: 0.9709 - val_loss: 0.7977 - val_accuracy: 0.7500 - lr: 5.0000e-06\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1489 - accuracy: 0.9658 - val_loss: 0.7911 - val_accuracy: 0.7524 - lr: 5.0000e-06\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1427 - accuracy: 0.9643 - val_loss: 0.7844 - val_accuracy: 0.7536 - lr: 5.0000e-06\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1549 - accuracy: 0.9607 - val_loss: 0.7779 - val_accuracy: 0.7548 - lr: 5.0000e-06\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1453 - accuracy: 0.9628 - val_loss: 0.7716 - val_accuracy: 0.7571 - lr: 5.0000e-06\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1382 - accuracy: 0.9628 - val_loss: 0.7652 - val_accuracy: 0.7583 - lr: 5.0000e-06\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1529 - accuracy: 0.9633 - val_loss: 0.7588 - val_accuracy: 0.7631 - lr: 5.0000e-06\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1537 - accuracy: 0.9607 - val_loss: 0.7523 - val_accuracy: 0.7643 - lr: 5.0000e-06\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1407 - accuracy: 0.9643 - val_loss: 0.7461 - val_accuracy: 0.7655 - lr: 5.0000e-06\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1371 - accuracy: 0.9684 - val_loss: 0.7399 - val_accuracy: 0.7667 - lr: 5.0000e-06\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1551 - accuracy: 0.9607 - val_loss: 0.7338 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1431 - accuracy: 0.9628 - val_loss: 0.7277 - val_accuracy: 0.7679 - lr: 5.0000e-06\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 0.1570 - accuracy: 0.9551 - val_loss: 0.7216 - val_accuracy: 0.7702 - lr: 5.0000e-06\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1442 - accuracy: 0.9607 - val_loss: 0.7157 - val_accuracy: 0.7726 - lr: 5.0000e-06\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1449 - accuracy: 0.9648 - val_loss: 0.7097 - val_accuracy: 0.7762 - lr: 5.0000e-06\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1496 - accuracy: 0.9597 - val_loss: 0.7040 - val_accuracy: 0.7798 - lr: 5.0000e-06\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1514 - accuracy: 0.9617 - val_loss: 0.6984 - val_accuracy: 0.7810 - lr: 5.0000e-06\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1541 - accuracy: 0.9612 - val_loss: 0.6930 - val_accuracy: 0.7833 - lr: 5.0000e-06\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1356 - accuracy: 0.9633 - val_loss: 0.6872 - val_accuracy: 0.7869 - lr: 5.0000e-06\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1541 - accuracy: 0.9607 - val_loss: 0.6817 - val_accuracy: 0.7893 - lr: 5.0000e-06\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1464 - accuracy: 0.9638 - val_loss: 0.6762 - val_accuracy: 0.7905 - lr: 5.0000e-06\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1763 - accuracy: 0.9577 - val_loss: 0.6706 - val_accuracy: 0.7940 - lr: 5.0000e-06\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1383 - accuracy: 0.9724 - val_loss: 0.6650 - val_accuracy: 0.7964 - lr: 5.0000e-06\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1427 - accuracy: 0.9587 - val_loss: 0.6598 - val_accuracy: 0.7976 - lr: 5.0000e-06\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1522 - accuracy: 0.9638 - val_loss: 0.6546 - val_accuracy: 0.7988 - lr: 5.0000e-06\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1565 - accuracy: 0.9592 - val_loss: 0.6494 - val_accuracy: 0.8012 - lr: 5.0000e-06\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1418 - accuracy: 0.9668 - val_loss: 0.6442 - val_accuracy: 0.8024 - lr: 5.0000e-06\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1457 - accuracy: 0.9653 - val_loss: 0.6389 - val_accuracy: 0.8036 - lr: 5.0000e-06\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1371 - accuracy: 0.9658 - val_loss: 0.6338 - val_accuracy: 0.8071 - lr: 5.0000e-06\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1528 - accuracy: 0.9602 - val_loss: 0.6287 - val_accuracy: 0.8095 - lr: 5.0000e-06\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1454 - accuracy: 0.9602 - val_loss: 0.6237 - val_accuracy: 0.8095 - lr: 5.0000e-06\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1518 - accuracy: 0.9622 - val_loss: 0.6187 - val_accuracy: 0.8107 - lr: 5.0000e-06\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1548 - accuracy: 0.9602 - val_loss: 0.6138 - val_accuracy: 0.8107 - lr: 5.0000e-06\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1327 - accuracy: 0.9658 - val_loss: 0.6089 - val_accuracy: 0.8131 - lr: 5.0000e-06\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1332 - accuracy: 0.9730 - val_loss: 0.6042 - val_accuracy: 0.8143 - lr: 5.0000e-06\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1441 - accuracy: 0.9628 - val_loss: 0.5995 - val_accuracy: 0.8167 - lr: 5.0000e-06\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1528 - accuracy: 0.9582 - val_loss: 0.5948 - val_accuracy: 0.8167 - lr: 5.0000e-06\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1461 - accuracy: 0.9679 - val_loss: 0.5902 - val_accuracy: 0.8190 - lr: 5.0000e-06\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1434 - accuracy: 0.9643 - val_loss: 0.5855 - val_accuracy: 0.8202 - lr: 5.0000e-06\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1484 - accuracy: 0.9633 - val_loss: 0.5810 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1397 - accuracy: 0.9679 - val_loss: 0.5763 - val_accuracy: 0.8214 - lr: 5.0000e-06\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1342 - accuracy: 0.9663 - val_loss: 0.5719 - val_accuracy: 0.8226 - lr: 5.0000e-06\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1469 - accuracy: 0.9633 - val_loss: 0.5674 - val_accuracy: 0.8238 - lr: 5.0000e-06\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1675 - accuracy: 0.9541 - val_loss: 0.5630 - val_accuracy: 0.8238 - lr: 5.0000e-06\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1439 - accuracy: 0.9633 - val_loss: 0.5586 - val_accuracy: 0.8286 - lr: 5.0000e-06\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1552 - accuracy: 0.9612 - val_loss: 0.5542 - val_accuracy: 0.8321 - lr: 5.0000e-06\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1511 - accuracy: 0.9582 - val_loss: 0.5500 - val_accuracy: 0.8321 - lr: 5.0000e-06\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1426 - accuracy: 0.9653 - val_loss: 0.5456 - val_accuracy: 0.8345 - lr: 5.0000e-06\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1421 - accuracy: 0.9582 - val_loss: 0.5414 - val_accuracy: 0.8345 - lr: 5.0000e-06\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.1408 - accuracy: 0.9668 - val_loss: 0.5372 - val_accuracy: 0.8357 - lr: 5.0000e-06\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1521 - accuracy: 0.9587 - val_loss: 0.5332 - val_accuracy: 0.8381 - lr: 5.0000e-06\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1565 - accuracy: 0.9597 - val_loss: 0.5291 - val_accuracy: 0.8405 - lr: 5.0000e-06\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1440 - accuracy: 0.9607 - val_loss: 0.5250 - val_accuracy: 0.8417 - lr: 5.0000e-06\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1429 - accuracy: 0.9653 - val_loss: 0.5210 - val_accuracy: 0.8440 - lr: 5.0000e-06\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1373 - accuracy: 0.9653 - val_loss: 0.5171 - val_accuracy: 0.8464 - lr: 5.0000e-06\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1527 - accuracy: 0.9607 - val_loss: 0.5132 - val_accuracy: 0.8476 - lr: 5.0000e-06\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1498 - accuracy: 0.9607 - val_loss: 0.5094 - val_accuracy: 0.8488 - lr: 5.0000e-06\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1589 - accuracy: 0.9597 - val_loss: 0.5056 - val_accuracy: 0.8488 - lr: 5.0000e-06\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1557 - accuracy: 0.9587 - val_loss: 0.5018 - val_accuracy: 0.8488 - lr: 5.0000e-06\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1463 - accuracy: 0.9628 - val_loss: 0.4980 - val_accuracy: 0.8488 - lr: 5.0000e-06\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1461 - accuracy: 0.9653 - val_loss: 0.4944 - val_accuracy: 0.8488 - lr: 5.0000e-06\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1315 - accuracy: 0.9684 - val_loss: 0.4907 - val_accuracy: 0.8500 - lr: 5.0000e-06\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.1543 - accuracy: 0.9582 - val_loss: 0.4871 - val_accuracy: 0.8512 - lr: 5.0000e-06\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.1506 - accuracy: 0.9577 - val_loss: 0.4836 - val_accuracy: 0.8512 - lr: 5.0000e-06\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1300 - accuracy: 0.9704 - val_loss: 0.4802 - val_accuracy: 0.8536 - lr: 5.0000e-06\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1471 - accuracy: 0.9622 - val_loss: 0.4767 - val_accuracy: 0.8548 - lr: 5.0000e-06\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1514 - accuracy: 0.9633 - val_loss: 0.4734 - val_accuracy: 0.8560 - lr: 5.0000e-06\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1406 - accuracy: 0.9684 - val_loss: 0.4700 - val_accuracy: 0.8560 - lr: 5.0000e-06\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1509 - accuracy: 0.9561 - val_loss: 0.4666 - val_accuracy: 0.8583 - lr: 5.0000e-06\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1467 - accuracy: 0.9638 - val_loss: 0.4632 - val_accuracy: 0.8595 - lr: 5.0000e-06\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1501 - accuracy: 0.9551 - val_loss: 0.4599 - val_accuracy: 0.8619 - lr: 5.0000e-06\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1464 - accuracy: 0.9653 - val_loss: 0.4566 - val_accuracy: 0.8631 - lr: 5.0000e-06\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1487 - accuracy: 0.9673 - val_loss: 0.4534 - val_accuracy: 0.8631 - lr: 5.0000e-06\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1434 - accuracy: 0.9617 - val_loss: 0.4502 - val_accuracy: 0.8631 - lr: 5.0000e-06\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1519 - accuracy: 0.9638 - val_loss: 0.4472 - val_accuracy: 0.8643 - lr: 5.0000e-06\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1422 - accuracy: 0.9612 - val_loss: 0.4441 - val_accuracy: 0.8667 - lr: 5.0000e-06\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1458 - accuracy: 0.9607 - val_loss: 0.4412 - val_accuracy: 0.8679 - lr: 5.0000e-06\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1464 - accuracy: 0.9622 - val_loss: 0.4383 - val_accuracy: 0.8690 - lr: 5.0000e-06\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1337 - accuracy: 0.9602 - val_loss: 0.4354 - val_accuracy: 0.8690 - lr: 5.0000e-06\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1444 - accuracy: 0.9643 - val_loss: 0.4325 - val_accuracy: 0.8702 - lr: 5.0000e-06\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1490 - accuracy: 0.9617 - val_loss: 0.4297 - val_accuracy: 0.8726 - lr: 5.0000e-06\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1494 - accuracy: 0.9612 - val_loss: 0.4269 - val_accuracy: 0.8726 - lr: 5.0000e-06\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 0.1522 - accuracy: 0.9577 - val_loss: 0.4240 - val_accuracy: 0.8738 - lr: 5.0000e-06\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 293ms/step - loss: 0.1368 - accuracy: 0.9668 - val_loss: 0.4211 - val_accuracy: 0.8738 - lr: 5.0000e-06\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 0.1477 - accuracy: 0.9638 - val_loss: 0.4182 - val_accuracy: 0.8738 - lr: 5.0000e-06\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1449 - accuracy: 0.9673 - val_loss: 0.4155 - val_accuracy: 0.8762 - lr: 5.0000e-06\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1484 - accuracy: 0.9633 - val_loss: 0.4128 - val_accuracy: 0.8762 - lr: 5.0000e-06\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1285 - accuracy: 0.9704 - val_loss: 0.4101 - val_accuracy: 0.8774 - lr: 5.0000e-06\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 0.1520 - accuracy: 0.9607 - val_loss: 0.4075 - val_accuracy: 0.8774 - lr: 5.0000e-06\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1358 - accuracy: 0.9638 - val_loss: 0.4049 - val_accuracy: 0.8786 - lr: 5.0000e-06\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1391 - accuracy: 0.9648 - val_loss: 0.4023 - val_accuracy: 0.8786 - lr: 5.0000e-06\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1394 - accuracy: 0.9638 - val_loss: 0.3999 - val_accuracy: 0.8786 - lr: 5.0000e-06\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1620 - accuracy: 0.9582 - val_loss: 0.3975 - val_accuracy: 0.8798 - lr: 5.0000e-06\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1416 - accuracy: 0.9633 - val_loss: 0.3951 - val_accuracy: 0.8798 - lr: 5.0000e-06\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1381 - accuracy: 0.9668 - val_loss: 0.3927 - val_accuracy: 0.8810 - lr: 5.0000e-06\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1562 - accuracy: 0.9587 - val_loss: 0.3904 - val_accuracy: 0.8821 - lr: 5.0000e-06\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1385 - accuracy: 0.9673 - val_loss: 0.3882 - val_accuracy: 0.8821 - lr: 5.0000e-06\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1365 - accuracy: 0.9679 - val_loss: 0.3859 - val_accuracy: 0.8821 - lr: 5.0000e-06\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1627 - accuracy: 0.9556 - val_loss: 0.3836 - val_accuracy: 0.8821 - lr: 5.0000e-06\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1389 - accuracy: 0.9648 - val_loss: 0.3814 - val_accuracy: 0.8845 - lr: 5.0000e-06\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.1453 - accuracy: 0.9673 - val_loss: 0.3791 - val_accuracy: 0.8845 - lr: 5.0000e-06\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1439 - accuracy: 0.9612 - val_loss: 0.3769 - val_accuracy: 0.8857 - lr: 5.0000e-06\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 0.1489 - accuracy: 0.9628 - val_loss: 0.3747 - val_accuracy: 0.8869 - lr: 5.0000e-06\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1497 - accuracy: 0.9612 - val_loss: 0.3725 - val_accuracy: 0.8869 - lr: 5.0000e-06\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1556 - accuracy: 0.9597 - val_loss: 0.3703 - val_accuracy: 0.8869 - lr: 5.0000e-06\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1534 - accuracy: 0.9612 - val_loss: 0.3681 - val_accuracy: 0.8869 - lr: 5.0000e-06\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1493 - accuracy: 0.9571 - val_loss: 0.3660 - val_accuracy: 0.8893 - lr: 5.0000e-06\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1474 - accuracy: 0.9577 - val_loss: 0.3639 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1443 - accuracy: 0.9582 - val_loss: 0.3619 - val_accuracy: 0.8905 - lr: 5.0000e-06\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1443 - accuracy: 0.9638 - val_loss: 0.3599 - val_accuracy: 0.8917 - lr: 5.0000e-06\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1521 - accuracy: 0.9571 - val_loss: 0.3578 - val_accuracy: 0.8917 - lr: 5.0000e-06\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1463 - accuracy: 0.9592 - val_loss: 0.3558 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1543 - accuracy: 0.9648 - val_loss: 0.3539 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1508 - accuracy: 0.9612 - val_loss: 0.3519 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1456 - accuracy: 0.9638 - val_loss: 0.3501 - val_accuracy: 0.8917 - lr: 5.0000e-06\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1418 - accuracy: 0.9643 - val_loss: 0.3481 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1539 - accuracy: 0.9612 - val_loss: 0.3462 - val_accuracy: 0.8929 - lr: 5.0000e-06\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1503 - accuracy: 0.9643 - val_loss: 0.3443 - val_accuracy: 0.8940 - lr: 5.0000e-06\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.1536 - accuracy: 0.9587 - val_loss: 0.3425 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1591 - accuracy: 0.9577 - val_loss: 0.3407 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1416 - accuracy: 0.9628 - val_loss: 0.3389 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1485 - accuracy: 0.9612 - val_loss: 0.3371 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1506 - accuracy: 0.9617 - val_loss: 0.3354 - val_accuracy: 0.8964 - lr: 5.0000e-06\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1454 - accuracy: 0.9643 - val_loss: 0.3337 - val_accuracy: 0.8952 - lr: 5.0000e-06\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1453 - accuracy: 0.9592 - val_loss: 0.3320 - val_accuracy: 0.8964 - lr: 5.0000e-06\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1403 - accuracy: 0.9638 - val_loss: 0.3303 - val_accuracy: 0.8964 - lr: 5.0000e-06\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1503 - accuracy: 0.9582 - val_loss: 0.3286 - val_accuracy: 0.8976 - lr: 5.0000e-06\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1343 - accuracy: 0.9643 - val_loss: 0.3270 - val_accuracy: 0.8988 - lr: 5.0000e-06\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1428 - accuracy: 0.9648 - val_loss: 0.3254 - val_accuracy: 0.8988 - lr: 5.0000e-06\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 0.1453 - accuracy: 0.9653 - val_loss: 0.3237 - val_accuracy: 0.9000 - lr: 5.0000e-06\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.1422 - accuracy: 0.9648 - val_loss: 0.3220 - val_accuracy: 0.9000 - lr: 5.0000e-06\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1427 - accuracy: 0.9633 - val_loss: 0.3204 - val_accuracy: 0.9036 - lr: 5.0000e-06\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1392 - accuracy: 0.9607 - val_loss: 0.3188 - val_accuracy: 0.9036 - lr: 5.0000e-06\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1470 - accuracy: 0.9592 - val_loss: 0.3172 - val_accuracy: 0.9036 - lr: 5.0000e-06\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1305 - accuracy: 0.9709 - val_loss: 0.3156 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1358 - accuracy: 0.9668 - val_loss: 0.3140 - val_accuracy: 0.9036 - lr: 5.0000e-06\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.1500 - accuracy: 0.9648 - val_loss: 0.3124 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1313 - accuracy: 0.9663 - val_loss: 0.3109 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1357 - accuracy: 0.9668 - val_loss: 0.3094 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1432 - accuracy: 0.9622 - val_loss: 0.3079 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1377 - accuracy: 0.9638 - val_loss: 0.3065 - val_accuracy: 0.9048 - lr: 5.0000e-06\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1291 - accuracy: 0.9704 - val_loss: 0.3051 - val_accuracy: 0.9060 - lr: 5.0000e-06\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1502 - accuracy: 0.9597 - val_loss: 0.3037 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1352 - accuracy: 0.9663 - val_loss: 0.3024 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1485 - accuracy: 0.9643 - val_loss: 0.3010 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1353 - accuracy: 0.9668 - val_loss: 0.2997 - val_accuracy: 0.9083 - lr: 5.0000e-06\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1459 - accuracy: 0.9587 - val_loss: 0.2984 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1608 - accuracy: 0.9561 - val_loss: 0.2972 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 0.1376 - accuracy: 0.9633 - val_loss: 0.2960 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1500 - accuracy: 0.9592 - val_loss: 0.2947 - val_accuracy: 0.9095 - lr: 5.0000e-06\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1432 - accuracy: 0.9679 - val_loss: 0.2935 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.1541 - accuracy: 0.9602 - val_loss: 0.2922 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1453 - accuracy: 0.9633 - val_loss: 0.2910 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1373 - accuracy: 0.9638 - val_loss: 0.2898 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1614 - accuracy: 0.9633 - val_loss: 0.2886 - val_accuracy: 0.9071 - lr: 5.0000e-06\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1417 - accuracy: 0.9612 - val_loss: 0.2874 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1597 - accuracy: 0.9597 - val_loss: 0.2862 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1360 - accuracy: 0.9653 - val_loss: 0.2850 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1496 - accuracy: 0.9638 - val_loss: 0.2839 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1420 - accuracy: 0.9622 - val_loss: 0.2828 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1443 - accuracy: 0.9612 - val_loss: 0.2817 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1465 - accuracy: 0.9628 - val_loss: 0.2806 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1467 - accuracy: 0.9653 - val_loss: 0.2795 - val_accuracy: 0.9107 - lr: 5.0000e-06\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1504 - accuracy: 0.9643 - val_loss: 0.2785 - val_accuracy: 0.9119 - lr: 5.0000e-06\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1461 - accuracy: 0.9658 - val_loss: 0.2774 - val_accuracy: 0.9119 - lr: 5.0000e-06\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1429 - accuracy: 0.9653 - val_loss: 0.2764 - val_accuracy: 0.9131 - lr: 5.0000e-06\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1440 - accuracy: 0.9628 - val_loss: 0.2753 - val_accuracy: 0.9167 - lr: 5.0000e-06\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1527 - accuracy: 0.9566 - val_loss: 0.2743 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1422 - accuracy: 0.9668 - val_loss: 0.2733 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1396 - accuracy: 0.9607 - val_loss: 0.2723 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1544 - accuracy: 0.9561 - val_loss: 0.2713 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1431 - accuracy: 0.9612 - val_loss: 0.2703 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1383 - accuracy: 0.9622 - val_loss: 0.2693 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1247 - accuracy: 0.9745 - val_loss: 0.2684 - val_accuracy: 0.9179 - lr: 5.0000e-06\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1251 - accuracy: 0.9730 - val_loss: 0.2674 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1373 - accuracy: 0.9643 - val_loss: 0.2664 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1550 - accuracy: 0.9587 - val_loss: 0.2655 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.1399 - accuracy: 0.9622 - val_loss: 0.2646 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1332 - accuracy: 0.9628 - val_loss: 0.2638 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1417 - accuracy: 0.9633 - val_loss: 0.2628 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 0.1471 - accuracy: 0.9582 - val_loss: 0.2620 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1394 - accuracy: 0.9648 - val_loss: 0.2611 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.1523 - accuracy: 0.9633 - val_loss: 0.2602 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1401 - accuracy: 0.9653 - val_loss: 0.2594 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1403 - accuracy: 0.9597 - val_loss: 0.2585 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1489 - accuracy: 0.9622 - val_loss: 0.2577 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1556 - accuracy: 0.9546 - val_loss: 0.2569 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1255 - accuracy: 0.9704 - val_loss: 0.2561 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1537 - accuracy: 0.9643 - val_loss: 0.2553 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 0.1578 - accuracy: 0.9597 - val_loss: 0.2546 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.1331 - accuracy: 0.9704 - val_loss: 0.2538 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1608 - accuracy: 0.9592 - val_loss: 0.2531 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1438 - accuracy: 0.9612 - val_loss: 0.2524 - val_accuracy: 0.9190 - lr: 5.0000e-06\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1379 - accuracy: 0.9694 - val_loss: 0.2517 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.1426 - accuracy: 0.9607 - val_loss: 0.2510 - val_accuracy: 0.9202 - lr: 5.0000e-06\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1384 - accuracy: 0.9633 - val_loss: 0.2503 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.1561 - accuracy: 0.9622 - val_loss: 0.2497 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1538 - accuracy: 0.9628 - val_loss: 0.2491 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1423 - accuracy: 0.9638 - val_loss: 0.2484 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1478 - accuracy: 0.9638 - val_loss: 0.2478 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1356 - accuracy: 0.9653 - val_loss: 0.2471 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1425 - accuracy: 0.9648 - val_loss: 0.2465 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1566 - accuracy: 0.9622 - val_loss: 0.2459 - val_accuracy: 0.9226 - lr: 5.0000e-06\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1411 - accuracy: 0.9673 - val_loss: 0.2453 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1353 - accuracy: 0.9633 - val_loss: 0.2447 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 0.1472 - accuracy: 0.9592 - val_loss: 0.2442 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1420 - accuracy: 0.9577 - val_loss: 0.2436 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1480 - accuracy: 0.9577 - val_loss: 0.2431 - val_accuracy: 0.9250 - lr: 5.0000e-06\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1388 - accuracy: 0.9638 - val_loss: 0.2425 - val_accuracy: 0.9262 - lr: 5.0000e-06\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.1326 - accuracy: 0.9714 - val_loss: 0.2420 - val_accuracy: 0.9262 - lr: 5.0000e-06\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1439 - accuracy: 0.9617 - val_loss: 0.2415 - val_accuracy: 0.9262 - lr: 5.0000e-06\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1484 - accuracy: 0.9633 - val_loss: 0.2410 - val_accuracy: 0.9262 - lr: 5.0000e-06\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1432 - accuracy: 0.9602 - val_loss: 0.2405 - val_accuracy: 0.9274 - lr: 5.0000e-06\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1268 - accuracy: 0.9668 - val_loss: 0.2401 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.1493 - accuracy: 0.9633 - val_loss: 0.2396 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.1252 - accuracy: 0.9689 - val_loss: 0.2391 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1444 - accuracy: 0.9633 - val_loss: 0.2387 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1449 - accuracy: 0.9628 - val_loss: 0.2383 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1466 - accuracy: 0.9668 - val_loss: 0.2379 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1330 - accuracy: 0.9653 - val_loss: 0.2375 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1515 - accuracy: 0.9612 - val_loss: 0.2371 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1496 - accuracy: 0.9617 - val_loss: 0.2367 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 0.1519 - accuracy: 0.9602 - val_loss: 0.2363 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1446 - accuracy: 0.9653 - val_loss: 0.2360 - val_accuracy: 0.9286 - lr: 5.0000e-06\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1373 - accuracy: 0.9663 - val_loss: 0.2356 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1409 - accuracy: 0.9638 - val_loss: 0.2352 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1420 - accuracy: 0.9648 - val_loss: 0.2348 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1312 - accuracy: 0.9633 - val_loss: 0.2345 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.1481 - accuracy: 0.9628 - val_loss: 0.2341 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 0.1407 - accuracy: 0.9679 - val_loss: 0.2337 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1297 - accuracy: 0.9689 - val_loss: 0.2334 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.1415 - accuracy: 0.9663 - val_loss: 0.2330 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1396 - accuracy: 0.9653 - val_loss: 0.2327 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1303 - accuracy: 0.9735 - val_loss: 0.2323 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1321 - accuracy: 0.9668 - val_loss: 0.2319 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1554 - accuracy: 0.9577 - val_loss: 0.2315 - val_accuracy: 0.9298 - lr: 5.0000e-06\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1402 - accuracy: 0.9612 - val_loss: 0.2312 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1367 - accuracy: 0.9684 - val_loss: 0.2308 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 0.1446 - accuracy: 0.9597 - val_loss: 0.2305 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1445 - accuracy: 0.9592 - val_loss: 0.2301 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1409 - accuracy: 0.9638 - val_loss: 0.2298 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1317 - accuracy: 0.9679 - val_loss: 0.2294 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1321 - accuracy: 0.9653 - val_loss: 0.2291 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 0.1432 - accuracy: 0.9643 - val_loss: 0.2288 - val_accuracy: 0.9310 - lr: 5.0000e-06\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.1381 - accuracy: 0.9694 - val_loss: 0.2285 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1496 - accuracy: 0.9617 - val_loss: 0.2282 - val_accuracy: 0.9321 - lr: 5.0000e-06\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.1425 - accuracy: 0.9648 - val_loss: 0.2279 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 0.1419 - accuracy: 0.9658 - val_loss: 0.2276 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 0.1325 - accuracy: 0.9699 - val_loss: 0.2274 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1483 - accuracy: 0.9607 - val_loss: 0.2272 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.1253 - accuracy: 0.9704 - val_loss: 0.2269 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.1336 - accuracy: 0.9643 - val_loss: 0.2267 - val_accuracy: 0.9333 - lr: 5.0000e-06\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.1528 - accuracy: 0.9597 - val_loss: 0.2264 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 0.1429 - accuracy: 0.9617 - val_loss: 0.2262 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.1534 - accuracy: 0.9612 - val_loss: 0.2260 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.1596 - accuracy: 0.9607 - val_loss: 0.2258 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.1438 - accuracy: 0.9622 - val_loss: 0.2256 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.1490 - accuracy: 0.9622 - val_loss: 0.2253 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1415 - accuracy: 0.9648 - val_loss: 0.2251 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.1434 - accuracy: 0.9628 - val_loss: 0.2249 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1538 - accuracy: 0.9561 - val_loss: 0.2248 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1514 - accuracy: 0.9617 - val_loss: 0.2246 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.1391 - accuracy: 0.9633 - val_loss: 0.2244 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1464 - accuracy: 0.9602 - val_loss: 0.2242 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1325 - accuracy: 0.9689 - val_loss: 0.2241 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1329 - accuracy: 0.9653 - val_loss: 0.2239 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1265 - accuracy: 0.9673 - val_loss: 0.2237 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.1227 - accuracy: 0.9730 - val_loss: 0.2235 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.1352 - accuracy: 0.9633 - val_loss: 0.2233 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1332 - accuracy: 0.9684 - val_loss: 0.2230 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.1470 - accuracy: 0.9628 - val_loss: 0.2229 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1434 - accuracy: 0.9643 - val_loss: 0.2227 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 0.1331 - accuracy: 0.9668 - val_loss: 0.2225 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.1436 - accuracy: 0.9643 - val_loss: 0.2224 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 0.1487 - accuracy: 0.9607 - val_loss: 0.2222 - val_accuracy: 0.9357 - lr: 5.0000e-06\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1381 - accuracy: 0.9673 - val_loss: 0.2221 - val_accuracy: 0.9345 - lr: 5.0000e-06\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.1460 - accuracy: 0.9628 - val_loss: 0.2219 - val_accuracy: 0.9345 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "DD_Net, training_history = train(DD_Net, X_train, Y_train, X_valid, Y_valid, epochs=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DD_Net.save_weights('../models/ddnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(training_history.history['accuracy'])\n",
    "plt.plot(training_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-03 04:44:17.562142: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 2s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.869699239730835"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "y = DD_Net.predict(X_train)\n",
    "time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = DD_Net.predict(X_valid)\n",
    "cnf_matrix = confusion_matrix(np.argmax(Y_valid, axis=1), np.argmax(Y_pred, axis=1))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cnf_matrix)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}